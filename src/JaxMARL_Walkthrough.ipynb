{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# JaxMARL Example Usage\n",
        "\n",
        "Welcome to a walkthrough of the JaxMARL repo. We include several popular MARL environemnts and algorithms, allowing you to easily evaluate your new approach! This colab will showcase our API, the speed of our environments and how to train over multiple seeds.\n",
        "\n",
        "⚠️ Ensure you select a GPU from `Runtime > Change runtime type` ⚠️"
      ],
      "metadata": {
        "id": "BjRnlRuH1654"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies 📚\n",
        "\n",
        "We install JAX for use with a GPU, there is rather a lot to download so this may take a second or two.\n"
      ],
      "metadata": {
        "id": "R_qy-SX12H5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJIaqAt40_rg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5715f3b-2ab0-4bd8-f468-b94adc2667c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax[cuda11_pip] in /usr/local/lib/python3.10/dist-packages (0.4.23)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (1.11.4)\n",
            "Collecting jaxlib==0.4.23+cuda11.cudnn86 (from jax[cuda11_pip])\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.23%2Bcuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl (129.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11>=11.11 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvcc-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11>=8.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cudnn_cu11-8.9.6.50-py3-none-manylinux1_x86_64.whl (699.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m699.9/699.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11>=10.9 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11>=11.4 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11>=11.7 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11>=2.18.3 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11 (from nvidia-cudnn-cu11>=8.8->jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.23+cuda12.cudnn89\n",
            "    Uninstalling jaxlib-0.4.23+cuda12.cudnn89:\n",
            "      Successfully uninstalled jaxlib-0.4.23+cuda12.cudnn89\n",
            "Successfully installed jaxlib-0.4.23+cuda11.cudnn86 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvcc-cu11-11.8.89 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.9.6.50 nvidia-cufft-cu11-10.9.0.58 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting jaxmarl\n",
            "  Downloading jaxmarl-0.0.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: jax>=0.4.11 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.4.23)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.7.5)\n",
            "Requirement already satisfied: chex>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.1.7)\n",
            "Collecting dotmap>=1.3.30 (from jaxmarl)\n",
            "  Downloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
            "Collecting evosax>=0.1.4 (from jaxmarl)\n",
            "  Downloading evosax-0.1.5-py3-none-any.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.6/144.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distrax>=0.1.3 (from jaxmarl)\n",
            "  Downloading distrax-0.1.5-py3-none-any.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=6.2.0 (from matplotlib)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brax>=0.9 (from jaxmarl)\n",
            "  Downloading brax-0.9.4-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnax>=0.0.6 (from jaxmarl)\n",
            "  Downloading gymnax-0.0.6-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.4/92.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.7.1 (from jaxmarl)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting wandb (from jaxmarl)\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.3.2 (from jaxmarl)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf>=2.3.0 (from jaxmarl)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.4.1)\n",
            "Requirement already satisfied: optax>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (1.4.0)\n",
            "Collecting dm-env (from brax>=0.9->jaxmarl)\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (1.6.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (2.2.5)\n",
            "Collecting flask-cors (from brax>=0.9->jaxmarl)\n",
            "  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (1.60.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (0.25.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (0.4.23+cuda11.cudnn86)\n",
            "Collecting jaxopt (from brax>=0.9->jaxmarl)\n",
            "  Downloading jaxopt-0.8.3-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (3.1.3)\n",
            "Collecting ml-collections (from brax>=0.9->jaxmarl)\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mujoco (from brax>=0.9->jaxmarl)\n",
            "  Downloading mujoco-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mujoco-mjx (from brax>=0.9->jaxmarl)\n",
            "  Downloading mujoco_mjx-3.1.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytinyrenderer (from brax>=0.9->jaxmarl)\n",
            "  Downloading pytinyrenderer-0.0.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (1.11.4)\n",
            "Collecting tensorboardX (from brax>=0.9->jaxmarl)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trimesh (from brax>=0.9->jaxmarl)\n",
            "  Downloading trimesh-4.1.0-py3-none-any.whl (689 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m690.0/690.0 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->jaxmarl) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->jaxmarl) (0.12.0)\n",
            "Collecting chex>=0.1.7 (from jaxmarl)\n",
            "  Downloading chex-0.1.85-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from distrax>=0.1.3->jaxmarl) (0.22.0)\n",
            "Collecting numpy>=1.20 (from matplotlib)\n",
            "  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from evosax>=0.1.4->jaxmarl) (6.0.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->jaxmarl) (1.0.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->jaxmarl) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->jaxmarl) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->jaxmarl) (13.7.0)\n",
            "Collecting gym (from brax>=0.9->jaxmarl)\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->jaxmarl)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.11->jaxmarl) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.11->jaxmarl) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->jaxmarl)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->jaxmarl)\n",
            "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->jaxmarl)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->jaxmarl)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (3.20.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->jaxmarl)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->brax>=0.9->jaxmarl) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->brax>=0.9->jaxmarl) (0.0.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->jaxmarl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->jaxmarl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->jaxmarl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->jaxmarl) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->jaxmarl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->jaxmarl) (2.16.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.3->jaxmarl) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.3->jaxmarl) (0.5.4)\n",
            "INFO: pip is looking at multiple versions of tensorflow-probability to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-probability>=0.15.0 (from distrax>=0.1.3->jaxmarl)\n",
            "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->brax>=0.9->jaxmarl) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->brax>=0.9->jaxmarl) (2.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->brax>=0.9->jaxmarl) (2.1.4)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections->brax>=0.9->jaxmarl) (21.6.0)\n",
            "Collecting glfw (from mujoco->brax>=0.9->jaxmarl)\n",
            "  Downloading glfw-2.6.5-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco->brax>=0.9->jaxmarl) (3.1.7)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->jaxmarl) (1.6.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->jaxmarl)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->jaxmarl) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils->brax>=0.9->jaxmarl) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils->brax>=0.9->jaxmarl) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils->brax>=0.9->jaxmarl) (3.17.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, gym, ml-collections\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=7b4c2e32b904ff9e57139810ebd0c46b601a191b6b059fb07f840fb440193a12\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827621 sha256=053fc95b3ab5c024bbe0999a116ff13fb47273c81d564ffdd45d4e3717f0af7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94505 sha256=914736aff2235e48d072ae562ba0be0bb14868513eb91917ca7ec722e4d8a81e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "Successfully built antlr4-python3-runtime gym ml-collections\n",
            "Installing collected packages: pytinyrenderer, glfw, dotmap, antlr4-python3-runtime, typing-extensions, smmap, setproctitle, sentry-sdk, pillow, omegaconf, numpy, ml-collections, docker-pycreds, trimesh, tensorflow-probability, tensorboardX, hydra-core, gym, gitdb, dm-env, GitPython, flask-cors, wandb, mujoco, jaxopt, chex, mujoco-mjx, distrax, gymnax, evosax, brax, jaxmarl\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.22.0\n",
            "    Uninstalling tensorflow-probability-0.22.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.22.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: chex\n",
            "    Found existing installation: chex 0.1.7\n",
            "    Uninstalling chex-0.1.7:\n",
            "      Successfully uninstalled chex-0.1.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.41 antlr4-python3-runtime-4.9.3 brax-0.9.4 chex-0.1.85 distrax-0.1.5 dm-env-1.6 docker-pycreds-0.4.0 dotmap-1.3.30 evosax-0.1.5 flask-cors-4.0.0 gitdb-4.0.11 glfw-2.6.5 gym-0.26.2 gymnax-0.0.6 hydra-core-1.3.2 jaxmarl-0.0.2 jaxopt-0.8.3 ml-collections-0.1.1 mujoco-3.1.1 mujoco-mjx-3.1.1 numpy-1.26.3 omegaconf-2.3.0 pillow-10.2.0 pytinyrenderer-0.0.14 sentry-sdk-1.39.2 setproctitle-1.3.3 smmap-5.0.1 tensorboardX-2.6.2.2 tensorflow-probability-0.23.0 trimesh-4.1.0 typing-extensions-4.9.0 wandb-0.16.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install matplotlib jaxmarl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: JaxMARL API 🕹️\n",
        "\n",
        "Our API is inspired by [PettingZoo](https://github.com/Farama-Foundation/PettingZoo) and [Gymnax](https://github.com/RobertTLange/gymnax), making it familiar to MARL researchers. Below, an MPE scenario is instatiated from JaxMARL's registry and a trajectory is sampled using random actions. We then visualise the results. Examples for more JaxMARL environments can be found [here](https://github.com/FLAIROx/JaxMARL/tree/main/jaxmarl/tutorials).\n",
        "\n",
        "* `actions`, `obs`, `rewards`, `dones` are dictionaries keyed by agent name, this allows for differing action and observation spaces. As agents can terminate asychronously, `dones` contains a special `\"__all__\"` which signifies whether an episode has terminated.\n",
        "* `state` represents the internal state of the environment and contains all the information needed to transistion the environment given a set of actions. These variables are not held within the environment class due to JAX transformations requiring pure functions.\n",
        "* `info` is a dictionary containing pertinent information, the exact content varies environment to environment.\n"
      ],
      "metadata": {
        "id": "uOaiuWkePf7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "import jax\n",
        "from jaxmarl import make\n",
        "from jaxmarl.environments.mpe import MPEVisualizer\n",
        "\n",
        "# Parameters + random keys\n",
        "max_steps = 25\n",
        "key = jax.random.PRNGKey(0)\n",
        "key, key_r, key_a = jax.random.split(key, 3)\n",
        "\n",
        "# Instantiate environment\n",
        "env = make('MPE_simple_reference_v3')\n",
        "obs, state = env.reset(key_r)\n",
        "print('list of agents in environment', env.agents)\n",
        "\n",
        "# Sample random actions\n",
        "key_a = jax.random.split(key_a, env.num_agents)\n",
        "actions = {agent: env.action_space(agent).sample(key_a[i]) for i, agent in enumerate(env.agents)}\n",
        "print('example action dict', actions)\n",
        "\n",
        "# Collect trajectory\n",
        "state_seq = []\n",
        "for _ in range(max_steps):\n",
        "    state_seq.append(state)\n",
        "    # Iterate random keys and sample actions\n",
        "    key, key_s, key_a = jax.random.split(key, 3)\n",
        "    key_a = jax.random.split(key_a, env.num_agents)\n",
        "    actions = {agent: env.action_space(agent).sample(key_a[i]) for i, agent in enumerate(env.agents)}\n",
        "\n",
        "    # Step environment\n",
        "    obs, state, rewards, dones, infos = env.step(key_s, state, actions)\n",
        "\n",
        "# Visualise\n",
        "viz = MPEVisualizer(env, state_seq)\n",
        "ani = animation.FuncAnimation(\n",
        "    viz.fig,\n",
        "    viz.update,\n",
        "    frames=len(viz.state_seq),\n",
        "    blit=False,\n",
        "    interval=viz.interval,\n",
        ")\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_html5_video())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h3VkMmsdPfc0",
        "outputId": "ca7f3e9b-9394-4ff8-fb1f-59868e11699c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list of agents in environment ['agent_0', 'agent_1']\n",
            "example action dict {'agent_0': Array(40, dtype=int32), 'agent_1': Array(37, dtype=int32)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return lax_numpy.astype(arr, dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return lax_numpy.astype(arr, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comm active?  True\n",
            "comm idx [0 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"500\" height=\"500\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAANcptZGF0AAACrgYF//+q\n",
              "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MyByMzA2MCA1ZGI2YWE2IC0gSC4yNjQvTVBF\n",
              "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMSAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
              "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
              "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
              "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
              "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMg\n",
              "bG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRl\n",
              "cmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJf\n",
              "cHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9\n",
              "MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3Jl\n",
              "ZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAu\n",
              "NjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAc\n",
              "m2WIhAAR//73iB8yy2n5OtdyEeetLq0fUO5GcV6kvf4gAAADAAAEdRzR55qyO2y7AAAFnABDAP/V\n",
              "+jn/mANQmRxsfOcxuJNQ2HE4tXAlX35AeljsMFCejAOlVB11VjiX5okHqg2rgZXLgere9joI6d8O\n",
              "faF4Wb29k+Qkv9/JQ6xHGs86eU9ineDsx04V0XatQrKk48npG9YJ2wH+QRnhHATf3KAB4Zj3D3oZ\n",
              "xrJ2O+H+scE8MLbN9lNXTt1DoBfn5cJNkyj45+G8dOBUoMTr1jUP2Q3REJzGUBLAlNysqnY8Ruen\n",
              "ebOD8BEhgMKKKsh8h8zrLBFhOYmbsqCJH+JTetieDQ0GS/5Vn9uVliQtYmrxwXpx988udRCWoxTJ\n",
              "YYVlAnGLeiNXp4Sfd69TPaPuythiJyD2xsM69Le9CpjpV4X5w4y8mYYt/yndBkgH9t52aF9cJubl\n",
              "8g8W8qZ+1th3entgeS+DNlyDZNFZiPRSASTgj/swDMKnkZA/lBaD7sws+J/srrhodjlR9eZgh12B\n",
              "1msUs/C4cGoNiL8cndyztzdC9Ezfjo0wQMUPpKEuuXeR+AsvzGZ/3biw9O2CzuGT23z6K00ig9gl\n",
              "5NHWU7wFMvW11epU4J3IGvrgbrVoVgaCrgvtoIekzb450grFfumyEcM7s32iMdTAPmBigx3DCOGh\n",
              "CzrPDUIk2SAOCEsgVqGOiivhxnHnYoGhCDXJqX5vMjdmEehZOeivWwbdscnBPFTb9ZTKFmUkq9qN\n",
              "XrCbC5ZLh16oj7eDZVCSA6v3y41BWnDJTBfSYYM/HfbyzrTLkpmVVxS5BAER4hTBS3NUuocX6lhw\n",
              "Ld2+r4NfDvHVvX/14wIoiIQf7OG4jYBYGI7ABYCujd430W62tM3iifkAiKVvcAkwWC7yUkxPj98F\n",
              "yluPF9rZ747euc/Q5Ivv9/snng9XnXlYZWJVj3byAW7NkwJGgZjAmApDxHUUoMfb2EA5SqUyAU8X\n",
              "jP9QF6tp8rfP8G0wcwOGzbSfhOdrCAdC+9GjZs1kLgq/pdrADQ2tBmUmfM4TBHjhuB8BU2M8f6DJ\n",
              "22KwKQlUrV1VdbmdA3a+jGSyxi76GsqnuDtm9axkM1Ur7M21FOJu/YXw7x/+u7F79ACQlc1fxZKD\n",
              "A+zI78U6aQtg3uU8vXzVdMefR8kdqLXe8rVvVs4/NWo5f/22TrnBCZejqsrXVwZRzZ6tJlpMQdNe\n",
              "YFe3GtFAFIMMyU7i36oEHyaI2dIgGMJvaGsALrsyq6h6r2ZTgulZA+orApQpGVXWgXYCKBNfUVtL\n",
              "iYK6GtiZLsLQiU1VdbZ0xu17GcyqvwIA8EE6ZqSVF4AJ9lDpOY3KSv8nIxrgzRY7mOX0BfmR+zau\n",
              "y3mgb1Mlb2/idEaS3XwKWT1azU7E+BWjTnB8//bWrx3RFzhPjoa9UFp8v8eZN8gf+rLQUYt6DEkG\n",
              "fQ+ehFPjil9hi0AnPeZqq3IOLmE5pTBalxP0C/GLjlQSow6ibjqNKKhlIyveeYnXuimPipqoJZxP\n",
              "SeM8QoZyEc4+DiGbupt5rsa20x/+fyp41U0oJgrx7BzPhxcOdbIM+S02S+Rak81Fy4DFnf2kHSsm\n",
              "+fTdk4cVUyZtJe2qm1IgDfDisjZJIaFuA8Spj/duFsGiKAuZ8Up1aFEkIF1jo7sAEaGDcymhC8JB\n",
              "DcZlU+JGwOZ1dtXUhSdYHCX8RjPGwPodW6fGT1cBIZHKmVvm25FHgjxl9TKLZExZywz7pjF4VTPk\n",
              "ujkMn/0Niwr3SA+JyF2uUlINEPCDmnxQMBqI9ZUFpv7y8FHZcbU3TOmNCX31c8H5KMXXjeq0Ygg4\n",
              "S0Z/gAqQ+lC9pA9EXvx07WM9PcUv8VyJhB31+US08tK/EUhcV/iv1VO1W2bvR6HYS/VH5UgHrTJu\n",
              "V1X/X/Y7d97DD5UnR2JHfI3v9jaX6iA3ACskppBuy6quBurVhG/mxnZTMwiCGYxkS8b8PvH9o3eu\n",
              "tcGAuTUJy/twtjv9ERiIJqq/RxQDJSecB6E52BpjZlZjfpQnrgQ8sDPOghrwJU5hCG/rVDXtoEJ7\n",
              "GHjX5cdYWQQaVD8qurn0S0z4/r1JaYgwLyW06w4IYTVc4/1uTxk73Tm4BOyccHk0TOxdp8vrvOj6\n",
              "6bxUOQFnqvRlXFPKaKjJRUCwjtZ/2VCKImc1uhBLbpQUe84Kqu+Vtem5XuXxvR1ZDiVRg014Zh2x\n",
              "C20ZZP8HIy9OxSctP0gY3cE3jxwxLWozUnFx568EYInn+QRzE74hGJrrJKgmZwIL5gD2YAoGQleF\n",
              "vMdXCn3I8qJm3L1m0rPpUSmaS7o6bB5UWpG05Z6QXYgIBswQSDsb3j/X+Gar7dPuuZ3Qvzav03+2\n",
              "0cxDKuyMK8DPuXB8M1mcXw9p73oQOyZks6NRpz57xgyTy8G21cYx1OMT1DfuM5BMExiFBaxlmXB6\n",
              "l8oR/m+LIkjLlId2a68GeSVXUDOV13U+T7yCVluOd2wiVA80WXRwjNmN4ucnCxE5RFvVcUa41lDo\n",
              "lIQ6qGNAfrG5LcrWYE0boYGrvMPemU3oFCjzcIE6d88KRYMmx9TTtU+X6Or1qz7ax0TfIWH28Tv/\n",
              "JKutGkT4tHj2qfkIkYrSC+iJDPgrGgWqWzX7+arN7iPJ+refq+zxgtv7ARH8KLcuK0El3HPP+UPf\n",
              "DiSEMej/h4C5/nk2/Dd7XwM0hL+qO1k62udLxroaZrWZ48wLt4v7jOWIp9ATHWho/VfKWzArXCsV\n",
              "fw1t3QNaGOSEdzeid5JAQg4aZ4+H9+6zkP5T/jiZs042mN/JTYzKuLoEgKBdIS4DpvHOS2R2SlL/\n",
              "vl/nMYXn7ppywRNtJE3rguXJXlduY+Kfekt/GRWFD2Mqv+pnKNiZViHTppZ0doKC9jrDImESN/XQ\n",
              "v+njINoCyazymBAFDNIOepm21b5QpYX62DQ7qla1uuq3jB/Lu6+Ycxf/W1gO9eaKUuQVxTMtI1Dr\n",
              "xP7ZrwpgVvlt4dZmcb6zF0FfA92s8mFMPY5miCnDRRDgmXQXaTJ3fkjcuHLrgILiFnDyzSPgcbSX\n",
              "EqeYc4L2yu6RQkVryNP82RNEpNgh9OnH1pRnZtcuIZtpgbxSShhzlPFguPYMPmltTcgfENEFp/bA\n",
              "iVHAVqqukseoiYNOBUEmm+xA604qkIH7gj8ANJuOBBIykqCf5XjfsIcxFBvhIvgp+gWHKReabgeS\n",
              "KhT/7enzONpJe4xPMx3DgfsiNQB9aV+m37zpI/+j1ayzTdB4WHR9q97ajhDGuybb9cv3iULc789M\n",
              "YwNNp0Am7PxGcr0pXw6dql3iuoLWsi6KX6xNjC0KghBKCf6r14o8hlQZ23vQIqzqWoMbBo2mRBeW\n",
              "Wfksw2d+PPrGmvpSY0BJCchudd3fPkhQ8l1rrfXXWq8zZ0uKg67gg1e1ULNM5GuiSzqqcgme20ZZ\n",
              "T7FQmJpKRMT9yTMS8sQEffSUQJ8ItX/vQ1TRdy9S+CTOOFLgu4TDeG2YdNixINCsBnVWGsE2jOl+\n",
              "pe4p6X4K4QqxxxIg25pTq7yJu5nG+qk2hI3OYzgNHdTFNtj36H18kBMEax5HvaaY3vVhn8kZtkMa\n",
              "y1jasLYNX86KYQWU7lxRkifkI8HzVHDt27KwKhMSzfYJe4NPEjGG0zuAfdBecVEjHtXC/oNj29Yh\n",
              "79WC+gsPaasDKsvvaBabMRvg/NMZTDmrCaWh2JTl7xsuEW0MFcv9lJjesxyCqLe8iNSvSG6zMMaK\n",
              "gKX+lf3eJ6ugDMLt7c64gTQ+Y1Rd2Fb+mlGf4UYBspba0/BO3GsA1hGmDdJupkokvv/CwN62k1QQ\n",
              "ryNh+To2NPSuui03M/AXAqehMCKtgdC3W918jpMbWk+33HXiap+N/yQbXtNcd76mcNKbA+6wFQ/X\n",
              "umhcK7qORvhGtOm4ziugX5h4d3Qcr3tSG04wn/f/0bqcNukM0c2LiAqS3hjZ9k+bzuZbB4E/OLqN\n",
              "fXL2ny4vmvZT9EjAFA7/IGp5HW+KFE33mSw9WqHXJzh/poWY8ZAe5UFwiDmqXtlcR70sn75D7W0s\n",
              "Xmloz1qij9KJCHzndHkG8aNT+b3Ap+XQ+BxNp7vOR27stiY+8H3KfB5iliZcBAb67p+6jxKtG/Qk\n",
              "607L+Cg+Rzh8ugcRZ0qSQeKdMwbTGRs5H43iZVP3uHEB+bdnEIsc522Q7yjpNwbtOhCRDfEAthy1\n",
              "b7uyT/RsFkon35pZ45QC1Ax/OMcZ4bDlEqao3ZLIrhMOB2bGAit+Vgz90v1LNtr0xauSFPZCq+F6\n",
              "NmVA9Mxz8ehNYFXLnZjxxg3g7JZwANqH6MkaBi4aMMixURCrtRaro1geKD/cYqRnF58rWph8gjDJ\n",
              "2JwV//VFTS/Kb8MUfkQVF+e8kvAkd2ivE9aD2lMzKCioaQTQcheo+pRP5VoxTz4xrJWm2N2aO0eI\n",
              "SALw0xdxRMeGsB5wmgsnlFh5w46Dr/KPPyXNg5JkJAuA+qHQ4XVwpjUPDN3AExAnYI6IbOm+7Ymj\n",
              "tl1mxnnX0ekMfplkIHWPR7QPaUYoMD8t6NiLutLYKyZFfnzZNHc34iqiH9kZNGjjlZTRJcEpjVCV\n",
              "7mH+ozyx8KQFnMVH5OllfzaHXbzvHEO+flIUXofCveiC1CP2NtvT/wi4JGAI5kiuQCQ04Vsv1/RM\n",
              "rzcJN/xRFFcYSmVjW5vtF/4nGTU1VeGccFxKmSF5HqGhSrfcYs5awWOTGe/+fyvchgJY7O+tIUEu\n",
              "l7WNQl6fdKZzdFWWtKEygmhOJ3JytFxWbglGklFh38LgvZ43gIsnvXYaChny+q0bHGn5L31m9EPT\n",
              "lZI2bFTODzX8BtUbjzDHXKQ8aqIOtq135pHQYWU4VgnxGJt9ar/wH9sDtUiMxJ89xcE/h2tT3chK\n",
              "lGD9TXi1aL87zVGVs+i8k/5rsMpGNzTn9wRUgOn2H36CXzze9XB6S5LVZZRvlbC+Hi4Irp4o3jlW\n",
              "Yxj+mVG9XSE48IAuvBsCDsbIGBXfnjKuTemcIUETbRvYKc99w/qH+hCqSKSLx/dzfJjNkXkf3q2g\n",
              "La2DEHSH7pp83Fu1kpl5/3avSysMuQc0ThE3ioqRehsUEiCC+9k5yCK6N+tDZ66dyStXKbM108dc\n",
              "sLEx2n1FTsbXD5mlTTPRT8bNjR9F32V8MoR/8+SAopUfmof47FY/3wtiorCFHtiClRE9OMqK9hR8\n",
              "zwL5ZLCOR090Wcl+WW/x2k2HKsjM39gyRkA50hokKDp2VtHrajHQh8fkTqiCjgmm9aC+Zl7lqiBk\n",
              "uWILGle/Q5FmdxCj4aoRJ3RgyKXU6b6Ubuh0gQdJsD9GjInbatewG8fIbCttyrbMUCEaGItWmMKy\n",
              "vsIDSYd1pd2jh6+NdskLFXKQ/yxM+RPGFJ6YHc2rAxGaw6Y+OELzIeCDfV/6rsN8XEC5f6ERg8rv\n",
              "oTJ2FMmOHVIq97u5ouPVnOru71vF7UHRzspv1BGF9zEVrPgGDVpCFel0feK8nX7FEz3tu0+cLE4Q\n",
              "SqePKJ8Phycis0kOgkgZjmG0cpVTP1U6vfDJNKaPI5Lkh0JR9WUx0irLZTiPIDEvFUm1As2bu6up\n",
              "W+YvAREJvdpce1PtrqGN6/Kd216gGL4yIw1W+5DKgkVpTLnAapjPc/1BKLCsbC5HsP6q5xNp+c/u\n",
              "Z+DUBHxuCa86tBksGbM+SXZej27rWSABYol+FAnp7wWoKsgDbqgaav7q1SQMHbNLkrjK9lROhbkO\n",
              "2ku8IKOg/T33X2mgGG7wQNYi22zdAL+3xHtU2rSVsAcS9JRJ6BCw9//x8KhNB5gExFYMyF4cul0z\n",
              "v4sGjBL3Ttx4yfHhA2aLCaNWxhzayJBnLY8K3X6ejUjM7vTwG0+gKSl0NoPI/6iaHiVjKWN339zz\n",
              "DRvqYtqeQETvDgZEmv17niaMbggvm+0XXVkF/O3p9G8lzztd8qGwO+fQHRr8ED9zr5Rj2vgRvqWO\n",
              "NipYZDWBVtFzK4uwTFPEA+nPIN2IMePOMXYiZZuNb5teudyo5TDKKtZb7JSh/ZkLAOuGagtASyH5\n",
              "XDk+8f2eQFKQiHoZZX7IKIUiT73J2xpW/3llkYbkErRoxFWfVvPNopnKlSuwsureb+Ttk9/+pkUg\n",
              "AYxc7UjYXsfFL7+BjQcNEwF20prFEKJSccO1lw4+yVw6M6mXb9YsGG6kxX76f+bvDR8o6G2JuLkm\n",
              "8MtYH98uAju60R+4t8K7oLXD9TKN+rd6U9GFw8uihaw7P1K3lKQK+AT5ufPp7G22MC+D4MezbKG9\n",
              "anf/sqGyQQUFaSi60L2ZoyGi3NByfzpSAvi4HFWfwalHZIpwAWH/sqp63MLJ+/0tDdTqSNNcBnk7\n",
              "+LKZEFpcS4Oy9MRDaoWFP92TLdWrzD0pkUJBTN2b8ZViAHQOqTE0ljgmOZrvAGbac99zA/xyRlKa\n",
              "zitAKGkaljY768yRcQW8YYj4yl5CRRsSoRr94R7EvspC6ocSxfq2/qtWmIJpk0aBgYG8ei5/2js2\n",
              "sTHGrngCA32p0REmMTHgnrgmvh6eXaJtAXUfztusVjetRcQC7bXjRz9l2cGeSUYbmIZvpw5WEdo0\n",
              "17EOAMCmY40Kq/35U+HIcs4BUfrzfXnqHyO6ISS3+RLyTOG4r0tAHpmnCgfGwaz7BmowoYPzi49k\n",
              "UyXX5Ar3dgFlqVfEvMO9Z0PHNc5eO99PU+2uoS1F+XFgKmWhtGuKXSADfVUAkVpTLohmLFVPVBqf\n",
              "mduUveGLwvbSn6lfpGZ89xfp5y6/JsM4lQRZHdAnZZRc2j6HJua49lcnmX3mw/qqrwRg2oK3QXQ+\n",
              "duskEqaP/w1zoeVgO0wf6I15aACncoRcN89I6k3nuFHqrx1Ms0jHf2Fxmxp7P//XK52YCd5UblEH\n",
              "xHXInQ1lPABrIz4oHH22lIMgTRFhe/oTKyHQnQqaKVMKuvvuBLpQvS4aU0+8hmGQOwNB3lpH0pSE\n",
              "4WbY9bN5dIErvczQCnXcpHJwe3Rvv+pCK/kdu9+b6pDtjG0WQYMqH3pUTcdzKGshk/KQOYd5xb+c\n",
              "F3nqttqRdw5TvCZsIVqPmAmNyGMyGO0a7K/uQbob1cQlKQvlIJ3aUNFPJgDDQLSrjRk5+bdhVwh8\n",
              "hJ0TFQa2cQ8YA9JlFy5MKLeYZWL4zq27DBOVWs+8BQcj/0wYZS3grQMYjo/9q9ophV1ev0tR0wVQ\n",
              "WA/l8bVbAuxf/be9whfLPi4CFTWjirnonv3o34x04jd6M0ABzKFHYDgJfXqPvC1FPfVNeFfXKM0b\n",
              "dnWVKJ3n9pt0/Niwb4Ny8VO3Ips6GrVXgHeSFAnaX/BV4aXhoygfQoXtu73tp2/W76VxMp88Or4L\n",
              "kIlm2AooUi0XCRM5NioDJTRFQpOhF4C/mhJXNhpTXOyfDtLr6IAGnZ43ZnXJHR8BCHZu7e+eZBIN\n",
              "e8/gNBpbr4y6vYnKcMV8KTpLHZ8/wpOgncrpEPBbvWenFMYpdVir5Vk7Fds2+DoDk7ZJQgjBKp6+\n",
              "eNeQOouWT3f2ptZSz5EW5bPO/epxgJdm9fyehgj/TqdLuuT4iHiShlUK9xpEqkjh1QCDEppOzaJL\n",
              "rQzMF6Xd8HA2N1pwoFzjPxALD/HhbkJuCgOzH4zhfx9UEsAMNCCXrD+GSsOQJe083rrPpqogvSLD\n",
              "lgZFMhKiUIMqC2yHhov//AlQoY6rd0zxDo6iyrTetS0Mtf7Vgf7RGAFVZUnN0fCj7mxFpyltzofW\n",
              "20Q4NSrJWkOboDQMV4388C7aAVIYoMGdclbOP+s1HyPh7iLcVs0bGdYCQnpuZQBlxCSX20+cGiVM\n",
              "a3NM8zEoF+XEv0Xo5FAj+f/lwM9TPr3KBjv6c7sPtHowF56oM8w0eawNPWVGg2jDJBBz/p1N+naE\n",
              "d6hS/br/VdwXoSXz2D/PTV84Sjpx3eoKj0HqfOJuMjFaXEbfyiJr2WjVDO2hNel7ahayEmpqvQs9\n",
              "L98M91cJNfb3bPTUhpdadScr/VcUdZ9LcRIdRhbrcpm6lVLSNBdz5bm6WkpFJDn1nt/uwq44lAlQ\n",
              "JZZrhKjs3I0GS+mv6jgE1sOH7IMClXpaXS/MQmV4Ih2e1V8OLu4otYZFm5QuePvml3veIgknCv75\n",
              "fft0cGPfrWWnvSpydL/wVWniel7O2k7ZCy7zRALfAixnqv+ECLgby/9ck9ZeProbsQjzjUxV0V0A\n",
              "ink4JaNwu50Rddwr7u1Q33iRYi7YvL/zuGbqAstRhdVFVdl25FZFQSE6opWeyIAdQKxmYzpTuYif\n",
              "eWMLP71O7dnHEBs7gftpWa90NQCGBna1+oI7+25nm2fkZdrDYb9CLul7QowZR6AgixS29nFt7jhu\n",
              "TD8/bnamZKDIiqHMLes/xzKzNxmRMbGaURHbStMrn6Sc24MaXaAO9lhjLWY2gjNU8G1J9CelLqd8\n",
              "6uDAdYS4k4zpthBlhszDfShrf5vLJ6CcJAYNZZb2mPOATdda+3l6QOIR1da80VXbw58UBF9XJhr5\n",
              "fjJqNPFUDVRbwFLYvN7Fpmf7sUSCnWtVUTHVuqVhCXGYBj/MtHHwaaNQv7W7zY8xKjAvixh9Gz3z\n",
              "2/jJdARttQlsqIO6EYF9MFWrkn4zmOd+TIYHsmJC2qvlHQYoKzgd0SbHbDT4Jrdc6jV2VtFekODP\n",
              "p9lngLmhdQCRSkOy5fyFQgNd7JqReMSsOVcAK9Kw3kvnO+Z2+Vh14jkWQjnDqsxTVv0JQvK50X3e\n",
              "SRiGhwydCwBHUyEK3BKoZNg8K1N4FsSndUmfxKPmjI6lCKm5bilsE2KR1mWB76n/0+R5yrPeYW40\n",
              "q/mN5CSgL/20yag+uVHr1FTBj+NO9AKyoWwLjuVd+BkNp1nOsZrtEKFEQ6NPCqzDEiwZ5TiUTw/R\n",
              "NCwEHI/aauE0b/ma/K9nQkKvsMEejrkumHZHRn3Xuw/iQUcRRApO+PbGoxQLbla1o27Tcp08e3Kg\n",
              "cUTaYJw7jxiERCyFJcIhVuDhwHzsZiKETvsZpyc7KPh+pNU/LfOLB0PlXshf2BarxvplrFVPpPIE\n",
              "5nwX/TjuDUfXXNNZGDkE1S4X9HsxOs9UpEI4qztkS9wRN8wMBA1ncmxcDKU30IW8RvCfTGWfdSsi\n",
              "gc7gC0i2FdFARS0oMwNjNbszBx2Bldjy7ECtppsfYhNETxFrIS9Rbl4Glui24JbgZA3mQNpH+/eq\n",
              "bbTt58vocvADGIYpPk0MZkd4MyTLQcl1ybmGiRfl5VqLhHnuHBu9MGrKEvl92fVEFlKLWQl5ZlPV\n",
              "aDmf+WHA2bzoUYFTLim761frNl1+NterkVAkAZ81to27/v9wdK0XN3V9WiLYYRhEYQKYH0rk+GiY\n",
              "4TKyIdsPqvmTtDwgbOEUPpDshi8cPwFrFy7jAh6PLOezvQZb8qDAYt9dJDDxGHtcX/BXjkUli8lD\n",
              "DykTQN/Ix006gpireo9lbdqbHYxQYsIYN8yAT4SjZuOMidbJEGgUPCUoWQVOh/lMxOiL/qyUwD5P\n",
              "XXpU4LbE98chB1Z4uPDC2dGtryqxiWy+b2gumfqHuymIZpeX5yBJ8yQQsRjbGGQmlwZRfY/qV+Hk\n",
              "nkM2zjLvGfpcass2XwW9KyR3qm09XHheu8aCdwxSB/BqZqccTz1fki8d+q7K/XhC+M9F3mrVCVGf\n",
              "iKKuVEw1V4LWctg1UeWvD4T5K4Vu//WOB1gYAhhEeQ+BFbVjjt8AAcOzy/RvwzL1oZNk3pS1mOx0\n",
              "kcjDhE422OOVrc471X8Ip1py8bBsK4BRmVrbtXNPBNF07sVwGkOLEOwtf50x6NTCeFP+2qSq5mGy\n",
              "zp3jjutUJqA5ndYTSfYHsgzpDQn4JWHDAAAXMQAAAYJBmiNsQR/+tSqAA+bjXgBFGRuD/wK+2Z2i\n",
              "Cg9otgZHRkhgamv3MIdrKQWlnKpjYBSXHyTwxAFoukyf7Zke88GmaKzcqQyazUXDTtaU61XxT5W/\n",
              "i3Y/+Ouw/2l7S4MH1lK7JmFOn1dDUYg/pEXP0uitxyGaCJr/2zOrMR5IRGi5+yFDeOzmyLL4aE0Y\n",
              "zHjIWIvbuXC90XSsK2PqyneXzFcGPvEeJNH0ZfRFUlw7oM3SG2LTi3eTJkBE4dkLOZbilBxtuBQh\n",
              "gOpNAkzaM+ZhOBFQ5A+4hx+foK5v9mZv6ppWhuI4eCmpNEfT1zlBgyO8lCHD1NsYaA1mQthRaHrS\n",
              "mAFR2p1nwi0QN8YqzvILWzkxdsf2DQjhACw9kCdpLazRuIsQLgIzt9FbZ/vg/q6Wkhq3nsFVWKzc\n",
              "29AIpsiHk3amjsNkkAfPoHLaKWzjMzGHZ4B0Qg66rO2ZIWqvu1Zw3xN6ThYpmJW/BFM0nURzrjg7\n",
              "A5ENkXRo47uhrLlb2BQ3UarZgAAAAKdBnkF4hv8AFiVdoAFyggwbyY0ozoqf7N+KGtrHo4Gd7qBo\n",
              "Cu+JLpPlMxwxmCLhI4JEP8Z1rkazw/zJ5JPToEm6TIt344c5EC/lLBEk9wTcm9QDGVqwY/fBifSq\n",
              "ac0Jt7CVOK8rNt933RMHbLabeSAduO2n3RJcfKz629nHVZ2LkYvKNAnJSWfqdyDkIJ4WjXjYrq+5\n",
              "wcdmH3cOt9UWvmdjsHhJ4YD0gQAAAMEBnmJqQ38AFifI3ACDE9/tuypDtTqzVqpLZEkw9pWTBl1N\n",
              "xlKjP+ozXH2e7918u8BjplcdSab3FnQ0tAcQS3dskmSRiiBTOED0XyEHxGhvtxDwyAZgqwRPBVeC\n",
              "cgs2gs/6AKxu7FFCN1/OUZsZZQZ9oH+36dqziXTs12PC8KPNbw9EcQkDQx39SO8xR0zf1m59oAfB\n",
              "FBRnegFfoHKltBFe/qkKJPuxUlb12M+xFpga/jz1/xAiW4ifAnbUTOof8vY0AAABKEGaZ0moQWiZ\n",
              "TAgj//61KoAD5mnIwBFGRuffMjdIqiSMOvuL8QfmGBaQJm3mj4ShzgnHBn4tbzjIn31CshtCATIq\n",
              "A0MoT/VbVoxOXcAvmzerIjY7n/wToVH5DUZaj9cXG+BPw0lgWAIOkCv2tffbLuM/B2+gtFroNCs4\n",
              "ogU6r3RM8Qf88c1EB7MB3zvQoyLnkJoViJ9CHZxY+0wq6Dy7Q9ES4PkIA12JkCfyspucpl29y+Bj\n",
              "chGZrbKyeUTFFJjaBQJT+N4xU4s+sdrS8OyUHVSfK+5fH1tSS1uVd3rzRTcflkY2mD1UgO5M55+Q\n",
              "tJEuXbSyODv3Z/HkLh51rsNZWwlG2DsOR3OYuhMDYXJBfzCjukvgEwg61ZBbv7CSd3xah4ZaQ84C\n",
              "/T7hAAAA0kGehUURLDv/AA9IEMWAFrvlYfhzU3V0Rd0C/HenbEEzZ9rQjm8cTYZ9oVbec5wsm3FU\n",
              "qAI/9Zi7GIfv26rmLOjsd/dkypXXxGdC+BoiDRQSDXdg+nnh2CRff0QVmH8TiEaLMcUiqFRHLspi\n",
              "8tntHhCSVdAq47WR14RI4fUfnj28Pv1Ygu4OVzSuwuESd+caOt67qZM6lSqe0aDhkDpQtJ/Oft3v\n",
              "xpVkEwrZNGO9d3yxhCUedhzj7omb1PyHoIeo0tc9YP5ZN3bJytVmXyavDDTGgQAAAJcBnqR0Q38A\n",
              "Fd3umOchAXztAB86Gv994iZ1N3VRGOfUV6OZztqqETYThp/drgou3oq6rYEexRumSe4C6Nh60FYX\n",
              "Z5dvDYrUKFPxdHMOotwq2kpWNrfaZjn2fmqBI8unMEq6MEP5cpLMFnqm3MGu8ajCuX+g5ERD5RB2\n",
              "ATwgx0qzbYOvcBvkoH3JIW1eY75f4TRj8XYi7dg5AAAA1AGepmpDfwAV3caSMMLlhQAIbKCM3Ucc\n",
              "ngILQHmOgmZW4BIz0rzi6ge4WfQA30qGUl5x/nyXfMfox86hZI/5ArPL9748Xbz3WyHALfKujYGO\n",
              "PcYhJBkx6ZWywS7I69SxfZ0/qTVjEN8HjwwNafD36NjwlxKOZ/wICKYN0tG5qV7c1/jZP59c496/\n",
              "cneIQCIuWh71xobZdRPHQHND9SyD+4WeFyhl0NcyPRg38zB58nEjSzoHERkTU+BTtmcprrvSh7Si\n",
              "YF0vlUpu9SdvvgeXeL4oR43pAAABgUGaq0moQWyZTAgj//61KoAD5k5Hh5rAEUaYuK2F/JzUGRQM\n",
              "MdzGbgKpD0gmcfkpsgPx6QD12XnYmwmbXh32iPIlieBkWuYxocyMHQI3/PikQG6KVBD/gRfPVoTk\n",
              "qYI4XtlwhmpBsYR9nA0n7gRyKyZORo5oOsAz9zv9kIxuzU5jqONihoHy9v1S0xsPSX/flNdzK9e9\n",
              "5aiTBi1FIVHNnsGyGSjQQYxybmhZrm1Xhe9TblnmRrtS/FzeWyt6c+WVKV+SY6qeqR6DZSiZWExq\n",
              "xSAdvifyMpjdkzCPzc3vUFjxsixF77iPp8NHzwFKFC3LZhkq78drvhkuY4rOIrgziQr2fGVV0ELZ\n",
              "iIzms7LMPbKBHcp1QiVLuCq0EJcg7tPxLTqpG4W3YKZ7R+237dME2vCImDhm8U59KDfdDN9T+Rjb\n",
              "++8NOPpz+PjhrNqAtNFR6MZN5WjK/JJNsJptduJHPM53XDVIknUq6bPQDEk186rdr835rlhg3Vfg\n",
              "unpJ39mwW0AAAACcQZ7JRRUsO/8AD0TY5pAB9osx/5bQ1k3k49kU1UTILJOdy7hQwDw8gZ+3Y3K8\n",
              "GV7sGzkRnTrz7qqCQ+n3D2yG3cWIdXDhKcqIvK/3GuP9RJjcU8njwarm4EZqo3GXTRn+Fng8zMlr\n",
              "mrke0JinLDSAQ5JbNrbL9PVIVHFqAs/Bz85AJtAEhmGmIjlwthDVHSNCUvbeD+e6d/sI/DJOAAAA\n",
              "rgGe6HRDfwAV3e5kCpMdABr7Zs9V/ljYOuCtDk5mQiSU4erZI+qyrv+oNyqvcWLGgnSjFbQusLHc\n",
              "v+zH3Mf5zpziHkUZ6LcGtohacOmN8qlBw5etrXMVUj1IPr7oO+InOf8bYETZDKq82xCt+YjAZq0J\n",
              "Ybb+8Fh59ajgZmmXr759TDuKBAwMGkTLuT1yNsorDE9Wp1gGF8Yt9r02sXskIbLgmJy3pArXmnLY\n",
              "3+FUkQAAAMEBnupqQ38AFiTTLC7j4AQWc/cx3Xn7MVob+f1BsIqW9tLiAzVs/g2M+fDOm2c/WqBg\n",
              "AvNAEXZ/c5ly9fv82LeGtRqbQc6HPROYbiaKNnOYwnCamso3ARrAQiI6VNEJUbIFhlzPA7KWmS9c\n",
              "gVXp242xBA4V1/qvBQ2z00P12ivhH088xH1msWD2VYelM5zWReXH9Af6jJVAtx74i/I83PomD00p\n",
              "DjYyONeEZJvBFee/SAgLmkTHLp5rc/jCrLdy/Fm9AAACYkGa70moQWyZTAgj//61KoAD0QuUAC9k\n",
              "HTJ5Zim78Eod4niDfr5T4HatTLKIyuar6rNCoX7qCH5np7JmisHqIuxaJLZxEYIZEDalpOSVLd85\n",
              "5DQcHhL/VWqA25FkmrIG/Js2srxFiPjBfCPc20/3xYcTWk2k9E6h5W3BN8mRLRlk/7Ft7Hn04HEv\n",
              "fbaPAYIxskVacSykbodAglub/rqwhxBbhCK9OSux3TQSEYqgE+SRsWAnNU2kdorW4MWscTNs9EXX\n",
              "RHzz3uzYwLqT/P2fFN7Kw5ipT3yqADHjL/RO0vkBmckJmUtF8k70a4M/8m3X1/P9xbwO5wa34E3H\n",
              "kd94Ii2+EI0T8TcIxW+O0JuDMgpHM6w9Sg5KDWk/WDUOgJoaB5v+qDhlpxubLWHTV4AQ6lvcw+iZ\n",
              "qTR9Z8aWdHuQjHWFmWxkrg1/JLAfsTbFLz47sgB9WprIzms5MveQUnhqHpy3ZQe1Jf/a5I2+I0kN\n",
              "TnzGX1ter91wIIYUVX55mlPceF6AxHug9Byky0lSToBj8mmLIj/09/E+AM3hTSY5MlSnbiUYU91U\n",
              "KOB/upubBX9hLRN3YTv5S2eZ4d4NKXS1gIFG5MR/vrJCtyBPTkgvP3A/gqkkVYIM+stvb4/PwE/6\n",
              "k2keROmUuxLlvY+vM7tlLVmGEqR3B80GfDm0fNwEC/shZbPS+6iZ/UqvZn+SnutHwohv+2xaguo9\n",
              "kVNf0C9VIGEUFiPZix0bOVYNVcBDN65L+YE2Yf1iUkCpSq9l9G48dXEdABUXdW60W+gpfMMuYVgx\n",
              "4yvYnutNIwhS7Z20FP/l6SAAAADSQZ8NRRUsO/8ADr6zwimVojBQAa+hGaXevuuPXD1KYwTw4fdk\n",
              "qdp8obnpZf63jCmTEK1JdAcZ6CwEqWIyO57Lv+0Df6hTpek7gYB4lMfBrSkgOaWgqsfPCZfzlvNV\n",
              "3IkXpMiDuffia2zT5/cYN747+Fy8uyNOr25dJWrDOVFgFsGJs1AJGZA4g9qCI1CQPFNNdUOuF6OC\n",
              "MlaiJt+JUGKFiqXCcjM3NXZE661CQGNsYsiityUrGb7MhBsnSSdsPlPexQYTPlYoz39Z+gX7sb5G\n",
              "IK2BAAAAoQGfLHRDfwAVSf4eewBAsAIQKLzN4CgSRlmXyoE5eun9dNbSwN5plZOrg7TPNL0dpIqt\n",
              "oeOaNWlpcTE07htUZf8Jyp31Bs0ma80OqjHtlWb8XX+W3cj0K7RhTS9Kkr/4Sk13D301LY2VjsRF\n",
              "qR5lDHf13nfgING6KfEmEenPq95Alpc8+bT4jI5qNkEQOBRW+gq0PB1utBgiaoPfeVS3blJBAAAA\n",
              "2AGfLmpDfwAVQt7XoRJxM2RTQAH8x/fuKB8Cx/IIuPc90peJ5a0oA1twMh2xvyXHMd6xaDMcFmt1\n",
              "fLSxsWRG3Es/UaFj+Qlha368jmJyQQVQzX80cJTvMdTKTiXjDQpfottHYhjKVdgGDrp79MtCcAwf\n",
              "MkycLIYwGFKvKwAoesRsY9dkX0bDPtz5+Z4V07yxRU2cidnnB9sgUrVMKv8Aq8EGmvkDPMjIEMWY\n",
              "WcTsoV1j7Sb8o2fK7Tou+adhFgLztCMwgogjOch1hEiBZfkqfiG4mynVMufMCQAAAO1BmzNJqEFs\n",
              "mUwIIf/+qlUAB6WVAiACG1Nf9kfhq8VNrCvsKaBT3wkxb4WjCVPjw5s5d3CQnPFXNNZAvrH7AaKS\n",
              "bX2e/GKJa8x+uBLZFr0N9EDVpFC3XJ0G+g3ikSI37qLeDxi4Esjch0DnL0leoPff183x9AJFsMoi\n",
              "GLoAfAZrjhUr3GJjdcEZvqMhQcfMP+llZSEQPKCl6nvoz95eyHdviiskeHAm8Zih9Rw3Qw3U6Dk3\n",
              "gVXR2uk6CvXBzwjOUEUwwQNIvi9tOo3tQvhZzonGBHsEM5IeY6uMrX+ZgaFny+e51JtFHeemI4Xl\n",
              "6SAAAAEvQZ9RRRUsO/8ADr9K+HqJhOxUADrwvVJ2CFWwkPVfi45x5I0cJYmwq/0hq5Hkw58IKZYt\n",
              "IJLY4hJVG13S2Mm66C9ANJyj6wHIbbZnHBPtnHhxhyNQBF4t071AHPdbVJ1/8IsmOaql15bS+K6A\n",
              "KKvNpsOAACzN9dXoen0JaZ2TFIS34ItKjgzOyw57pCz1N9GcNvbB++si+UzpZTS8N9Bfc3QNIbyH\n",
              "h69OzpFjwurfFD+4YOwljAKX5yHYUbMS9OnWeDc1jEWO+uHTMCxGTNZ7h+9uyzM9VghRegTWcEhw\n",
              "l8KRPcNqMhqC81PjYggaJXAev4nPU3BL5/0lnRU9usYuVXZLL+Xw9Y786FfVaxk7BsY8/wj9VTe8\n",
              "O11mtJGvvuU2oJbZPGsngxxsFV7+EuuAAAAAwgGfcHRDfwAVVZiKABDgui+wTFV4U9igY9LIR+GT\n",
              "Pt1fRKg8wvgftpu/51SluLM1rAZNzwvGsbNu2byte5it5B3ZFLjz9N8HKJ3Rx0Uy1Dk3/eqlSB3u\n",
              "uUogJCpiQEbKFxqPFIOprDdT5JnSqaonwLYSP9H6CZ6POqTpx+H7XYWXKPCIqUjl/MjCA4Y6VlIE\n",
              "cfPul68YdiNDb2qjAiO0tHmXmV6Zo5r77PRjDigA+vZqmmCfwr7OdpDLhZwwh8GT/LmfAAAArQGf\n",
              "cmpDfwAVQOvuZuEFpgA1lnVl/guCWiqw9CPn0qQkXiK3aW62CaPhHtupCzTOvS7YKiT6UnLeiCsl\n",
              "fkY3/7UQnj5wfMEeo74UQicj0V+xuzjLT/ARo3xVmRIrlkr8aIc20KqQZHC6TfjruSE0pA70FfcW\n",
              "GRFfUnI2X7ZnBDdku5wtdfcdwCe/3Aj07SJ+Ac7TJ8tHelPT6t9VzZMsfWKaBVf7EjUfDUyO9uOC\n",
              "AAABFkGbd0moQWyZTAh3//6plgAefddaoDnAA/NhEeHH7N0OBvsOxMR5uzWQpxgSdFJT2pcsdzKV\n",
              "8b4uIh51JEUVdtwmJ1f6wBWn7PDToNsPkmhYGsv5feRGxeekkjB4Wd9daqG84MX1z1WuC9My+45c\n",
              "4giWW0eagwOFOreVcHiBP7MiV5FMO2SnR9um/CBcEWiNcBD7suS6BKelBj86ZSPRIb50M/81YxYV\n",
              "fo2lBEgIWynO7r/FAJx0TKpesLw1F7qeGX0rktOMFN7+YQdaPeh3GBjj7ttCEXWTIUvvcN82cnaa\n",
              "wvVXITf+P/QKnlMotOvEaMD94+3sAyKyOjV3WNLvGIX7P1Ce7AVtcb91SFVzjjawOGi3BMHpAAAA\n",
              "y0GflUUVLDv/AA9GfMJ7mY+mEAEFmRV7uRp6hLlDHTi9gpbjYEHe0ULt9Sqt5fwqNtKMQbEs+7aY\n",
              "9xkqutSz70X3Lgg3HyWrgOyyNuhBfhKa3snsRHQr/j7/3Zm7ZM+gME0UUzq+iWflPD+tX6zTTS4R\n",
              "1nM6clYI2Wf+kEIvRfrl53aJ+S/PPEcK6BibMmQh64kSb0aXWm2oZ1XqmJG7waQsYDqnj6QxSpes\n",
              "nIqwJ390BuM0nyHZMAiQdtd7YLXJIyBFTAJQdqTidxsxAAAAiQGftHRDfwAWI7Z0VLgAIY9Zvx4Y\n",
              "tB6Hl8ZkTtgb66WC8I6ChMoOX2Du2j6TP0JqvS0uual1yvQfEJWSqrwk2obyTXccQkDD6kKnS830\n",
              "3W1E8ZcjWqrGL09tmBQi9JLrlCRTdW9lf4sOwAQHYVOOnk/1GW7RbFg5ETKmo9UTHviIprx2zQT2\n",
              "7Ds7AAAAwQGftmpDfwAVSfwVdbz/kQOwAhAos1L1EXo3xcOwuykHL2SFMK0eXLnmTB6GQh3OytEK\n",
              "FgiYa6FkKTfV8ytL+JxEHA8JbS3Tn4bXbeTP9Zc9dGKFu/iMCCErHJOG1DSlRI92cUpcK+znyvjH\n",
              "5R30/oDyyv/gYdMZoYUAPZLvEdDSTqxXcIOkZQ/KpUEZakCn1rPpISCvoZft7RGKOtkCagqE4bnv\n",
              "m8LWQX4yI7fwmQJu3j8/GVT7xDn79lzhelT1560AAADTQZu4SahBbJlMCG///qeEADs4/UdXcynI\n",
              "gAQ4g3TAAEsFu7HcjR6ly+BxrP3llwXxgS57+mkjzOM2UPOtBb9PHZspiB9sNsEV+Gc+gTmwGqiL\n",
              "ae+WKfDz1fZ+vBqH0Dq1BTf/1LX74M05nTxAS5H6Lh+29UoAC6mg+UmxB4ghg1aHbBS+inkSJy/M\n",
              "v5QYEEDIjF56D+//pYZ4vinbJgw9EcCABjJpQOgW/bDWbmXZeBEti3oSWT4RPNtYuyZyzZBAZjiz\n",
              "SSrmY5G1MpPG04nkLCWlBQAABFhtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAJxAABAAAB\n",
              "AAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAAAAAAAAAACAAADgnRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAJ\n",
              "xAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAB9AAA\n",
              "AfQAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAACcQAAAgAAAEAAAAAAvptZGlhAAAAIG1kaGQA\n",
              "AAAAAAAAAAAAAAAAACgAAABkAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZp\n",
              "ZGVvSGFuZGxlcgAAAAKlbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAA\n",
              "AAAAAAABAAAADHVybCAAAAABAAACZXN0YmwAAAC5c3RzZAAAAAAAAAABAAAAqWF2YzEAAAAAAAAA\n",
              "AQAAAAAAAAAAAAAAAAAAAAAB9AH0AEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAAY//8AAAA3YXZjQwFkABb/4QAaZ2QAFqzZQIAQeeeEAAADAAQAAAMAUDxYtlgB\n",
              "AAZo6+PLIsD9+PgAAAAAHHV1aWRraEDyXyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEA\n",
              "AAAZAAAEAAAAABRzdHNzAAAAAAAAAAEAAAABAAAA0GN0dHMAAAAAAAAAGAAAAAEAAAgAAAAAAQAA\n",
              "EAAAAAACAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAI\n",
              "AAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQA\n",
              "AAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAA\n",
              "AAABAAAIAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAGQAAAAEAAAB4c3RzegAAAAAAAAAAAAAAGQAA\n",
              "H1EAAAGGAAAAqwAAAMUAAAEsAAAA1gAAAJsAAADYAAABhQAAAKAAAACyAAAAxQAAAmYAAADWAAAA\n",
              "pQAAANwAAADxAAABMwAAAMYAAACxAAABGgAAAM8AAACNAAAAxQAAANcAAAAUc3RjbwAAAAAAAAAB\n",
              "AAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAA\n",
              "AAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguNzYuMTAw\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Compare speed 🚀\n",
        "\n",
        "We can then compare the speed of JaxMARL's MPE environments to the CPU-based ones provided by PettingZoo. We again take random actions and compare the number of environment steps per second between the two implementations.\n",
        "\n",
        "We also show how JaxMARL environments can be simply vectorised, using `jax.vmap`, to greatly increase the number of environment steps per second."
      ],
      "metadata": {
        "id": "XAIcs7kw2ROo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MPE_ENV = \"MPE_simple_reference_v3\""
      ],
      "metadata": {
        "id": "n_y9AyBcUU8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import jaxmarl\n",
        "import jax\n",
        "\n",
        "def make_benchmark(config):\n",
        "    env = jaxmarl.make(config[\"ENV_NAME\"], **config[\"ENV_KWARGS\"])\n",
        "    config[\"NUM_ACTORS\"] = env.num_agents * config[\"NUM_ENVS\"]\n",
        "\n",
        "    def benchmark(rng):\n",
        "        def init_runner_state(rng):\n",
        "\n",
        "            # INIT ENV\n",
        "            rng, _rng = jax.random.split(rng)\n",
        "            reset_rng = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
        "            obsv, env_state = jax.vmap(env.reset)(reset_rng)\n",
        "\n",
        "            return (env_state, obsv, rng)\n",
        "\n",
        "        def env_step(runner_state, unused):\n",
        "            env_state, last_obs, rng = runner_state\n",
        "\n",
        "            # SELECT ACTION\n",
        "            rng, _rng = jax.random.split(rng)\n",
        "            rngs = jax.random.split(_rng, config[\"NUM_ACTORS\"]).reshape((env.num_agents, config[\"NUM_ENVS\"], -1))\n",
        "            actions = {k: jax.vmap(env.action_space(k).sample)(rngs[i]) for i, k in enumerate(env.agents)}\n",
        "\n",
        "            # STEP ENV\n",
        "            rng, _rng = jax.random.split(rng)\n",
        "            rng_step = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
        "            obsv, env_state, _, _, info = jax.vmap(env.step)(\n",
        "                rng_step, env_state, actions\n",
        "            )\n",
        "            runner_state = (env_state, obsv, rng)\n",
        "            return runner_state, None\n",
        "\n",
        "        rng, init_rng = jax.random.split(rng)\n",
        "        runner_state = init_runner_state(init_rng)\n",
        "        runner_state = jax.lax.scan(env_step, runner_state, None, config[\"NUM_STEPS\"])\n",
        "        return runner_state\n",
        "\n",
        "    return benchmark"
      ],
      "metadata": {
        "id": "oRhtSTpYRg83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jaxmarl.environments.mpe.simple_world_comm import SimpleWorldCommMPE\n",
        "from pettingzoo.mpe import simple_v3, simple_tag_v3, simple_world_comm_v3, simple_reference_v3, simple_spread_v3, simple_crypto_v3, simple_speaker_listener_v4, simple_push_v3, simple_adversary_v3\n",
        "import time\n",
        "\n",
        "config = {\n",
        "    \"NUM_STEPS\": 1000,\n",
        "    \"NUM_ENVS\": 1000,\n",
        "    \"ACTIVATION\": \"relu\",\n",
        "    \"ENV_KWARGS\": {},\n",
        "    \"ENV_NAME\": MPE_ENV,\n",
        "    \"NUM_SEEDS\": 1,\n",
        "    \"SEED\": 0,\n",
        "}\n",
        "\n",
        "### JAXMARL BENCHMARK\n",
        "num_envs = [1, 100, 1000, 10000]\n",
        "jaxmarl_sps = []\n",
        "for num in num_envs:\n",
        "  config[\"NUM_ENVS\"] = num\n",
        "  benchmark_fn = jax.jit(make_benchmark(config))\n",
        "  rng = jax.random.PRNGKey(config[\"SEED\"])\n",
        "  rng, _rng = jax.random.split(rng)\n",
        "  benchmark_jit = jax.jit(benchmark_fn).lower(_rng).compile()\n",
        "  before = time.perf_counter_ns()\n",
        "  runner_state = jax.block_until_ready(benchmark_jit(_rng))\n",
        "  after = time.perf_counter_ns()\n",
        "  total_time = (after - before) / 1e9\n",
        "\n",
        "  sps = config['NUM_STEPS'] * config['NUM_ENVS'] / total_time\n",
        "  jaxmarl_sps.append(sps)\n",
        "\n",
        "  print(f\"JaxMARL, Num Envs: {num}, Total Time (s): {total_time}\")\n",
        "  print(f\"JaxMARL, Num Envs: {num}, Total Steps: {config['NUM_STEPS'] * config['NUM_ENVS']}\")\n",
        "  print(f\"JaxMARL, Num Envs: {num}, SPS: {sps}\")\n",
        "\n",
        "\n",
        "### PETTING ZOO BENCHMARK\n",
        "zoo_mpe_env_mapper = {\n",
        "    \"MPE_simple_v3\": simple_v3,\n",
        "    \"MPE_simple_world_comm_v3\": simple_world_comm_v3,\n",
        "    \"MPE_simple_tag_v3\": simple_tag_v3,\n",
        "    \"MPE_simple_spread_v3\": simple_spread_v3,\n",
        "    \"MPE_simple_crypto_v3\": simple_crypto_v3,\n",
        "    \"MPE_simple_speaker_listener_v4\": simple_speaker_listener_v4,\n",
        "    \"MPE_simple_push_v3\": simple_push_v3,\n",
        "    \"MPE_simple_adversary_v3\": simple_adversary_v3,\n",
        "    \"MPE_simple_reference_v3\": simple_reference_v3,\n",
        "}\n",
        "zoo_env = zoo_mpe_env_mapper[config[\"ENV_NAME\"]]\n",
        "env = zoo_env.parallel_env(max_cycles=max_steps)\n",
        "obs = env.reset()\n",
        "\n",
        "start_time = time.time()\n",
        "actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
        "\n",
        "for _ in range(config[\"NUM_STEPS\"]):\n",
        "    actions = {agent: env.action_space(agent).sample() for agent in env.agents}  # this is where you would insert your policy\n",
        "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
        "\n",
        "zoo_time = time.time() - start_time\n",
        "zoo_sps = config[\"NUM_STEPS\"]/zoo_time\n",
        "\n",
        "\n",
        "print(f\"PettingZoo Total Time (s): {zoo_time}\")\n",
        "print(f\"PettingZoo Total Steps: {config['NUM_STEPS']}\")\n",
        "print(f\"PettingZoo SPS: {zoo_sps}\")\n"
      ],
      "metadata": {
        "id": "h9VtVKgbRyMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(num_envs, jaxmarl_sps, linestyle='--', marker='o', label=\"JAX\")\n",
        "plt.axhline(y=zoo_sps, color='r', linestyle='--', label=\"PettingZoo\")\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel(\"Steps per Second\")\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Number of parallel environments\")\n",
        "plt.title(f\"Steps per second for {MPE_ENV}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6YLL7Aj-ShER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Train an agent 🍲\n",
        "\n",
        "We train an agent on the `cramped_room` Overcooked scenario using IPPO, our IPPO code is based off [PureJaxRL](https://github.com/luchris429/purejaxrl). Here we also show how `jax.vmap` can again be used to simply train over multiple seeds."
      ],
      "metadata": {
        "id": "WobTKkl25IlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import numpy as np\n",
        "import optax\n",
        "from flax.linen.initializers import constant, orthogonal\n",
        "from typing import Sequence, NamedTuple, Any\n",
        "from flax.training.train_state import TrainState\n",
        "import distrax\n",
        "from gymnax.wrappers.purerl import LogWrapper, FlattenObservationWrapper\n",
        "import jaxmarl\n",
        "from jaxmarl.wrappers.baselines import LogWrapper\n",
        "from jaxmarl.environments.overcooked import overcooked_layouts\n",
        "from jaxmarl.viz.overcooked_visualizer import OvercookedVisualizer\n",
        "import hydra\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    action_dim: Sequence[int]\n",
        "    activation: str = \"tanh\"\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        if self.activation == \"relu\":\n",
        "            activation = nn.relu\n",
        "        else:\n",
        "            activation = nn.tanh\n",
        "        actor_mean = nn.Dense(\n",
        "            64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
        "        )(x)\n",
        "        actor_mean = activation(actor_mean)\n",
        "        actor_mean = nn.Dense(\n",
        "            64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
        "        )(actor_mean)\n",
        "        actor_mean = activation(actor_mean)\n",
        "        actor_mean = nn.Dense(\n",
        "            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\n",
        "        )(actor_mean)\n",
        "        pi = distrax.Categorical(logits=actor_mean)\n",
        "\n",
        "        critic = nn.Dense(\n",
        "            64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
        "        )(x)\n",
        "        critic = activation(critic)\n",
        "        critic = nn.Dense(\n",
        "            64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
        "        )(critic)\n",
        "        critic = activation(critic)\n",
        "        critic = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(\n",
        "            critic\n",
        "        )\n",
        "\n",
        "        return pi, jnp.squeeze(critic, axis=-1)\n",
        "\n",
        "\n",
        "class Transition(NamedTuple):\n",
        "    done: jnp.ndarray\n",
        "    action: jnp.ndarray\n",
        "    value: jnp.ndarray\n",
        "    reward: jnp.ndarray\n",
        "    log_prob: jnp.ndarray\n",
        "    obs: jnp.ndarray\n",
        "    info: jnp.ndarray\n",
        "\n",
        "def get_rollout(train_state, config):\n",
        "    env = jaxmarl.make(config[\"ENV_NAME\"], **config[\"ENV_KWARGS\"])\n",
        "\n",
        "    network = ActorCritic(env.action_space().n, activation=config[\"ACTIVATION\"])\n",
        "    key = jax.random.PRNGKey(0)\n",
        "    key, key_r, key_a = jax.random.split(key, 3)\n",
        "\n",
        "    init_x = jnp.zeros(env.observation_space().shape)\n",
        "    init_x = init_x.flatten()\n",
        "\n",
        "    network.init(key_a, init_x)\n",
        "    network_params = train_state.params\n",
        "\n",
        "    done = False\n",
        "\n",
        "    obs, state = env.reset(key_r)\n",
        "    state_seq = [state]\n",
        "    while not done:\n",
        "        key, key_a0, key_a1, key_s = jax.random.split(key, 4)\n",
        "\n",
        "        # obs_batch = batchify(obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "        # breakpoint()\n",
        "        obs = {k: v.flatten() for k, v in obs.items()}\n",
        "\n",
        "        pi_0, _ = network.apply(network_params, obs[\"agent_0\"])\n",
        "        pi_1, _ = network.apply(network_params, obs[\"agent_1\"])\n",
        "\n",
        "        actions = {\"agent_0\": pi_0.sample(seed=key_a0), \"agent_1\": pi_1.sample(seed=key_a1)}\n",
        "        # env_act = unbatchify(action, env.agents, config[\"NUM_ENVS\"], env.num_agents)\n",
        "        # env_act = {k: v.flatten() for k, v in env_act.items()}\n",
        "\n",
        "        # STEP ENV\n",
        "        obs, state, reward, done, info = env.step(key_s, state, actions)\n",
        "        done = done[\"__all__\"]\n",
        "\n",
        "        state_seq.append(state)\n",
        "\n",
        "    return state_seq\n",
        "\n",
        "def batchify(x: dict, agent_list, num_actors):\n",
        "    x = jnp.stack([x[a] for a in agent_list])\n",
        "    return x.reshape((num_actors, -1))\n",
        "\n",
        "\n",
        "def unbatchify(x: jnp.ndarray, agent_list, num_envs, num_actors):\n",
        "    x = x.reshape((num_actors, num_envs, -1))\n",
        "    return {a: x[i] for i, a in enumerate(agent_list)}\n",
        "\n",
        "def make_train(config):\n",
        "    env = jaxmarl.make(config[\"ENV_NAME\"], **config[\"ENV_KWARGS\"])\n",
        "\n",
        "    config[\"NUM_ACTORS\"] = env.num_agents * config[\"NUM_ENVS\"]\n",
        "    config[\"NUM_UPDATES\"] = (\n",
        "        config[\"TOTAL_TIMESTEPS\"] // config[\"NUM_STEPS\"] // config[\"NUM_ENVS\"]\n",
        "    )\n",
        "    config[\"MINIBATCH_SIZE\"] = (\n",
        "        config[\"NUM_ACTORS\"] * config[\"NUM_STEPS\"] // config[\"NUM_MINIBATCHES\"]\n",
        "    )\n",
        "\n",
        "    env = LogWrapper(env)\n",
        "\n",
        "    def linear_schedule(count):\n",
        "        frac = 1.0 - (count // (config[\"NUM_MINIBATCHES\"] * config[\"UPDATE_EPOCHS\"])) / config[\"NUM_UPDATES\"]\n",
        "        return config[\"LR\"] * frac\n",
        "\n",
        "    def train(rng):\n",
        "\n",
        "        # INIT NETWORK\n",
        "        network = ActorCritic(env.action_space().n, activation=config[\"ACTIVATION\"])\n",
        "        rng, _rng = jax.random.split(rng)\n",
        "        init_x = jnp.zeros(env.observation_space().shape)\n",
        "\n",
        "        init_x = init_x.flatten()\n",
        "\n",
        "        network_params = network.init(_rng, init_x)\n",
        "        if config[\"ANNEAL_LR\"]:\n",
        "            tx = optax.chain(\n",
        "                optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
        "                optax.adam(learning_rate=linear_schedule, eps=1e-5),\n",
        "            )\n",
        "        else:\n",
        "            tx = optax.chain(optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]), optax.adam(config[\"LR\"], eps=1e-5))\n",
        "        train_state = TrainState.create(\n",
        "            apply_fn=network.apply,\n",
        "            params=network_params,\n",
        "            tx=tx,\n",
        "        )\n",
        "\n",
        "        # INIT ENV\n",
        "        rng, _rng = jax.random.split(rng)\n",
        "        reset_rng = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
        "        obsv, env_state = jax.vmap(env.reset, in_axes=(0,))(reset_rng)\n",
        "\n",
        "        # TRAIN LOOP\n",
        "        def _update_step(runner_state, unused):\n",
        "            # COLLECT TRAJECTORIES\n",
        "            def _env_step(runner_state, unused):\n",
        "                train_state, env_state, last_obs, rng = runner_state\n",
        "\n",
        "                # SELECT ACTION\n",
        "                rng, _rng = jax.random.split(rng)\n",
        "\n",
        "                obs_batch = batchify(last_obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "\n",
        "                pi, value = network.apply(train_state.params, obs_batch)\n",
        "                action = pi.sample(seed=_rng)\n",
        "                log_prob = pi.log_prob(action)\n",
        "                env_act = unbatchify(action, env.agents, config[\"NUM_ENVS\"], env.num_agents)\n",
        "\n",
        "                env_act = {k:v.flatten() for k,v in env_act.items()}\n",
        "\n",
        "                # STEP ENV\n",
        "                rng, _rng = jax.random.split(rng)\n",
        "                rng_step = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
        "\n",
        "                obsv, env_state, reward, done, info = jax.vmap(env.step, in_axes=(0,0,0))(\n",
        "                    rng_step, env_state, env_act\n",
        "                )\n",
        "                info = jax.tree_map(lambda x: x.reshape((config[\"NUM_ACTORS\"])), info)\n",
        "                transition = Transition(\n",
        "                    batchify(done, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
        "                    action,\n",
        "                    value,\n",
        "                    batchify(reward, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
        "                    log_prob,\n",
        "                    obs_batch,\n",
        "                    info\n",
        "\n",
        "                )\n",
        "                runner_state = (train_state, env_state, obsv, rng)\n",
        "                return runner_state, transition\n",
        "\n",
        "            runner_state, traj_batch = jax.lax.scan(\n",
        "                _env_step, runner_state, None, config[\"NUM_STEPS\"]\n",
        "            )\n",
        "\n",
        "            # CALCULATE ADVANTAGE\n",
        "            train_state, env_state, last_obs, rng = runner_state\n",
        "            last_obs_batch = batchify(last_obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "            _, last_val = network.apply(train_state.params, last_obs_batch)\n",
        "\n",
        "            def _calculate_gae(traj_batch, last_val):\n",
        "                def _get_advantages(gae_and_next_value, transition):\n",
        "                    gae, next_value = gae_and_next_value\n",
        "                    done, value, reward = (\n",
        "                        transition.done,\n",
        "                        transition.value,\n",
        "                        transition.reward,\n",
        "                    )\n",
        "                    delta = reward + config[\"GAMMA\"] * next_value * (1 - done) - value\n",
        "                    gae = (\n",
        "                        delta\n",
        "                        + config[\"GAMMA\"] * config[\"GAE_LAMBDA\"] * (1 - done) * gae\n",
        "                    )\n",
        "                    return (gae, value), gae\n",
        "\n",
        "                _, advantages = jax.lax.scan(\n",
        "                    _get_advantages,\n",
        "                    (jnp.zeros_like(last_val), last_val),\n",
        "                    traj_batch,\n",
        "                    reverse=True,\n",
        "                    unroll=16,\n",
        "                )\n",
        "                return advantages, advantages + traj_batch.value\n",
        "\n",
        "            advantages, targets = _calculate_gae(traj_batch, last_val)\n",
        "\n",
        "            # UPDATE NETWORK\n",
        "            def _update_epoch(update_state, unused):\n",
        "                def _update_minbatch(train_state, batch_info):\n",
        "                    traj_batch, advantages, targets = batch_info\n",
        "\n",
        "                    def _loss_fn(params, traj_batch, gae, targets):\n",
        "                        # RERUN NETWORK\n",
        "                        pi, value = network.apply(params, traj_batch.obs)\n",
        "                        log_prob = pi.log_prob(traj_batch.action)\n",
        "\n",
        "                        # CALCULATE VALUE LOSS\n",
        "                        value_pred_clipped = traj_batch.value + (\n",
        "                            value - traj_batch.value\n",
        "                        ).clip(-config[\"CLIP_EPS\"], config[\"CLIP_EPS\"])\n",
        "                        value_losses = jnp.square(value - targets)\n",
        "                        value_losses_clipped = jnp.square(value_pred_clipped - targets)\n",
        "                        value_loss = (\n",
        "                            0.5 * jnp.maximum(value_losses, value_losses_clipped).mean()\n",
        "                        )\n",
        "\n",
        "                        # CALCULATE ACTOR LOSS\n",
        "                        ratio = jnp.exp(log_prob - traj_batch.log_prob)\n",
        "                        gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n",
        "                        loss_actor1 = ratio * gae\n",
        "                        loss_actor2 = (\n",
        "                            jnp.clip(\n",
        "                                ratio,\n",
        "                                1.0 - config[\"CLIP_EPS\"],\n",
        "                                1.0 + config[\"CLIP_EPS\"],\n",
        "                            )\n",
        "                            * gae\n",
        "                        )\n",
        "                        loss_actor = -jnp.minimum(loss_actor1, loss_actor2)\n",
        "                        loss_actor = loss_actor.mean()\n",
        "                        entropy = pi.entropy().mean()\n",
        "\n",
        "                        total_loss = (\n",
        "                            loss_actor\n",
        "                            + config[\"VF_COEF\"] * value_loss\n",
        "                            - config[\"ENT_COEF\"] * entropy\n",
        "                        )\n",
        "                        return total_loss, (value_loss, loss_actor, entropy)\n",
        "\n",
        "                    grad_fn = jax.value_and_grad(_loss_fn, has_aux=True)\n",
        "                    total_loss, grads = grad_fn(\n",
        "                        train_state.params, traj_batch, advantages, targets\n",
        "                    )\n",
        "                    train_state = train_state.apply_gradients(grads=grads)\n",
        "                    return train_state, total_loss\n",
        "\n",
        "                train_state, traj_batch, advantages, targets, rng = update_state\n",
        "                rng, _rng = jax.random.split(rng)\n",
        "                batch_size = config[\"MINIBATCH_SIZE\"] * config[\"NUM_MINIBATCHES\"]\n",
        "                assert (\n",
        "                    batch_size == config[\"NUM_STEPS\"] * config[\"NUM_ACTORS\"]\n",
        "                ), \"batch size must be equal to number of steps * number of actors\"\n",
        "                permutation = jax.random.permutation(_rng, batch_size)\n",
        "                batch = (traj_batch, advantages, targets)\n",
        "                batch = jax.tree_util.tree_map(\n",
        "                    lambda x: x.reshape((batch_size,) + x.shape[2:]), batch\n",
        "                )\n",
        "                shuffled_batch = jax.tree_util.tree_map(\n",
        "                    lambda x: jnp.take(x, permutation, axis=0), batch\n",
        "                )\n",
        "                minibatches = jax.tree_util.tree_map(\n",
        "                    lambda x: jnp.reshape(\n",
        "                        x, [config[\"NUM_MINIBATCHES\"], -1] + list(x.shape[1:])\n",
        "                    ),\n",
        "                    shuffled_batch,\n",
        "                )\n",
        "                train_state, total_loss = jax.lax.scan(\n",
        "                    _update_minbatch, train_state, minibatches\n",
        "                )\n",
        "                update_state = (train_state, traj_batch, advantages, targets, rng)\n",
        "                return update_state, total_loss\n",
        "\n",
        "            update_state = (train_state, traj_batch, advantages, targets, rng)\n",
        "            update_state, loss_info = jax.lax.scan(\n",
        "                _update_epoch, update_state, None, config[\"UPDATE_EPOCHS\"]\n",
        "            )\n",
        "            train_state = update_state[0]\n",
        "            metric = traj_batch.info\n",
        "            rng = update_state[-1]\n",
        "\n",
        "            runner_state = (train_state, env_state, last_obs, rng)\n",
        "            return runner_state, metric\n",
        "\n",
        "        rng, _rng = jax.random.split(rng)\n",
        "        runner_state = (train_state, env_state, obsv, _rng)\n",
        "        runner_state, metric = jax.lax.scan(\n",
        "            _update_step, runner_state, None, config[\"NUM_UPDATES\"]\n",
        "        )\n",
        "        return {\"runner_state\": runner_state, \"metrics\": metric}\n",
        "\n",
        "    return train\n",
        "\n"
      ],
      "metadata": {
        "id": "wGwk68jK2VPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# set hyperparameters:\n",
        "config = {\n",
        "    \"LR\": 2.5e-4,\n",
        "    \"NUM_ENVS\": 16,\n",
        "    \"NUM_STEPS\": 128,\n",
        "    \"TOTAL_TIMESTEPS\": 5e6,\n",
        "    \"UPDATE_EPOCHS\": 4,\n",
        "    \"NUM_MINIBATCHES\": 4,\n",
        "    \"GAMMA\": 0.99,\n",
        "    \"GAE_LAMBDA\": 0.95,\n",
        "    \"CLIP_EPS\": 0.2,\n",
        "    \"ENT_COEF\": 0.01,\n",
        "    \"VF_COEF\": 0.5,\n",
        "    \"MAX_GRAD_NORM\": 0.5,\n",
        "    \"ACTIVATION\": \"tanh\",\n",
        "    \"ENV_NAME\": \"overcooked\",\n",
        "    \"ENV_KWARGS\": {\n",
        "      \"layout\" : \"cramped_room\"\n",
        "    },\n",
        "    \"ANNEAL_LR\": True,\n",
        "    \"SEED\": 0,\n",
        "    \"NUM_SEEDS\": 3\n",
        "}\n",
        "\n",
        "config[\"ENV_KWARGS\"][\"layout\"] = overcooked_layouts[config[\"ENV_KWARGS\"][\"layout\"]]\n",
        "rng = jax.random.PRNGKey(config[\"SEED\"])\n",
        "rngs = jax.random.split(rng, config[\"NUM_SEEDS\"])\n",
        "with jax.disable_jit(False):\n",
        "    train_jit = jax.jit(jax.vmap(make_train(config)))\n",
        "    out = train_jit(rngs)\n",
        "\n",
        "\n",
        "for i in range(config[\"NUM_SEEDS\"]):\n",
        "    plt.plot(out[\"metrics\"][\"returned_episode_returns\"][i].mean(-1).reshape(-1))\n",
        "plt.xlabel(\"Update Step\")\n",
        "plt.ylabel(\"Return\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AxrH1jHv3orP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.animation as animation\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import distrax\n",
        "from jaxmarl import make\n",
        "from jaxmarl.environments.smax import map_name_to_scenario\n",
        "from jaxmarl.environments.smax.heuristic_enemy import (\n",
        "    create_heuristic_policy,\n",
        "    get_heuristic_policy_initial_state,\n",
        ")\n",
        "from jaxmarl.viz.visualizer import Visualizer, SMAXVisualizer\n",
        "import os\n",
        "from typing import Sequence\n",
        "\n",
        "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "# Parameters + random keys\n",
        "max_steps = 30\n",
        "key = jax.random.PRNGKey(2)\n",
        "key, key_r, key_a, key_p = jax.random.split(key, 4)\n",
        "\n",
        "\n",
        "class LearnedPolicy(nn.Module):\n",
        "    action_dim: Sequence[int]\n",
        "    activation: str = \"tanh\"\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        if self.activation == \"relu\":\n",
        "            activation = nn.relu\n",
        "        else:\n",
        "            activation = nn.tanh\n",
        "        actor_mean = nn.Dense(self.action_dim)(x)\n",
        "        actor_mean = activation(actor_mean)\n",
        "        pi = distrax.Categorical(logits=actor_mean)\n",
        "\n",
        "        critic = nn.Dense(1)(x)\n",
        "        critic = activation(critic)\n",
        "\n",
        "        return pi, jnp.squeeze(critic, axis=-1)\n",
        "\n",
        "\n",
        "def init_policy(env, rng):\n",
        "    network = LearnedPolicy(env.action_space(env.agents[0]).n, activation=\"tanh\")\n",
        "    rng, _rng = jax.random.split(rng)\n",
        "    init_x = jnp.zeros(env.observation_space(env.agents[0]).shape)\n",
        "    params = network.init(_rng, init_x)\n",
        "    return params\n",
        "\n",
        "\n",
        "# Instantiate environment\n",
        "with jax.disable_jit(False):\n",
        "    # scenario = map_name_to_scenario(\"5m_vs_6m\")\n",
        "    env = make(\n",
        "        \"SMAX\",\n",
        "        # attack_mode=\"random\",\n",
        "        # scenario=scenario,\n",
        "        use_self_play_reward=False,\n",
        "        walls_cause_death=True,\n",
        "        see_enemy_actions=False,\n",
        "        num_allies=3,\n",
        "        num_enemies=5,\n",
        "        smacv2_position_generation=True,\n",
        "        smacv2_unit_type_generation=True,\n",
        "    )\n",
        "    # env = make(\"SMAX\")\n",
        "    # params = init_policy(env, key_p)\n",
        "    # learned_policy = LearnedPolicy(env.action_space(env.agents[0]).n, activation=\"tanh\")\n",
        "    # env = make(\"LearnedPolicyEnemySMAX\", params=params, policy=learned_policy)\n",
        "    obs, state = env.reset(key_r)\n",
        "    print(\"list of agents in environment\", env.agents)\n",
        "\n",
        "    # Sample random actions\n",
        "    key_a = jax.random.split(key_a, env.num_agents)\n",
        "    actions = {\n",
        "        agent: env.action_space(agent).sample(key_a[i])\n",
        "        for i, agent in enumerate(env.agents)\n",
        "    }\n",
        "    print(\"example action dict\", actions)\n",
        "\n",
        "    policy_states = {\n",
        "        agent: get_heuristic_policy_initial_state() for agent in env.agents\n",
        "    }\n",
        "    policy = create_heuristic_policy(env, 0, shoot=True, attack_mode=\"closest\")\n",
        "    enemy_policy = create_heuristic_policy(env, 1, shoot=True, attack_mode=\"closest\")\n",
        "    state_seq = []\n",
        "    returns = {a: 0 for a in env.agents}\n",
        "    for i in range(max_steps):\n",
        "        # Iterate random keys and sample actions\n",
        "        key, key_s, key_seq = jax.random.split(key, 3)\n",
        "        key_a = jax.random.split(key_seq, env.num_agents)\n",
        "        actions = {}\n",
        "        for i, agent in enumerate(env.agents):\n",
        "            p = policy if i < env.num_allies else enemy_policy\n",
        "            action, policy_state = p(key_a[i], policy_states[agent], obs[agent])\n",
        "            policy_states[agent] = policy_state\n",
        "            actions[agent] = action\n",
        "\n",
        "        # actions = {agent: jnp.array(1) for agent in env.agents}\n",
        "        # actions = {agent: env.action_space(agent).sample(key_a[i]) for i, agent in enumerate(env.agents)}\n",
        "        state_seq.append((key_s, state, actions))\n",
        "        # Step environment\n",
        "        avail_actions = env.get_avail_actions(state)\n",
        "        obs, state, rewards, dones, infos = env.step(key_s, state, actions)\n",
        "        print(f\"Actions: {actions}\")\n",
        "        returns = {a: returns[a] + rewards[a] for a in env.agents}\n",
        "        if dones[\"__all__\"]:\n",
        "            print(f\"Returns: {returns}\")\n",
        "print(f\"Returns: {returns}\")\n",
        "\n",
        "#viz.animate(view=False, save_fname=\"output.gif\")\n",
        "viz.animate(view=True)\n",
        "\n",
        "\"\"\"\n",
        "viz = SMAXVisualizer(env, state_seq)\n",
        "ani = animation.FuncAnimation(\n",
        "    viz.fig,\n",
        "    viz.update,\n",
        "    frames=len(viz.state_seq),\n",
        "    blit=False,\n",
        "    interval=viz.interval,\n",
        ")\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_html5_video())\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "lN6EBp3EtKNq",
        "outputId": "53436111-fc61-4c70-86f2-d058d8554668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list of agents in environment ['ally_0', 'ally_1', 'ally_2', 'enemy_0', 'enemy_1', 'enemy_2', 'enemy_3', 'enemy_4']\n",
            "example action dict {'ally_0': Array(3, dtype=int32), 'ally_1': Array(6, dtype=int32), 'ally_2': Array(3, dtype=int32), 'enemy_0': Array(6, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(2, dtype=int32), 'enemy_3': Array(0, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(5, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(1, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(5, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(3, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(6, dtype=int32)}\n",
            "Returns: {'ally_0': Array(0.44500005, dtype=float32), 'ally_1': Array(0.44500005, dtype=float32), 'ally_2': Array(0.44500005, dtype=float32), 'enemy_0': Array(2., dtype=float32), 'enemy_1': Array(2., dtype=float32), 'enemy_2': Array(2., dtype=float32), 'enemy_3': Array(2., dtype=float32), 'enemy_4': Array(2., dtype=float32)}\n",
            "Actions: {'ally_0': Array(3, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(2, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(0, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(0, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(2, dtype=int32), 'enemy_0': Array(1, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(1, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(5, dtype=int32)}\n",
            "Actions: {'ally_0': Array(3, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(1, dtype=int32), 'enemy_1': Array(5, dtype=int32), 'enemy_2': Array(1, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(5, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(5, dtype=int32), 'enemy_1': Array(5, dtype=int32), 'enemy_2': Array(1, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(5, dtype=int32)}\n",
            "Actions: {'ally_0': Array(3, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(1, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(1, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(6, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(6, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(6, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(2, dtype=int32), 'enemy_1': Array(2, dtype=int32), 'enemy_2': Array(2, dtype=int32), 'enemy_3': Array(2, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(3, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(2, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(2, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(1, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(2, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(2, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Returns: {'ally_0': Array(0.52825, dtype=float32), 'ally_1': Array(0.52825, dtype=float32), 'ally_2': Array(0.52825, dtype=float32), 'enemy_0': Array(4., dtype=float32), 'enemy_1': Array(4., dtype=float32), 'enemy_2': Array(4., dtype=float32), 'enemy_3': Array(4., dtype=float32), 'enemy_4': Array(4., dtype=float32)}\n",
            "Actions: {'ally_0': Array(1, dtype=int32), 'ally_1': Array(0, dtype=int32), 'ally_2': Array(1, dtype=int32), 'enemy_0': Array(3, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(3, dtype=int32), 'enemy_3': Array(3, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(2, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(1, dtype=int32), 'enemy_0': Array(2, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(3, dtype=int32), 'enemy_3': Array(0, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Returns: {'ally_0': Array(0.52825, dtype=float32), 'ally_1': Array(0.52825, dtype=float32), 'ally_2': Array(0.52825, dtype=float32), 'enemy_0': Array(4., dtype=float32), 'enemy_1': Array(4., dtype=float32), 'enemy_2': Array(4., dtype=float32), 'enemy_3': Array(4., dtype=float32), 'enemy_4': Array(4., dtype=float32)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/matplotlib/animation.py:884: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nviz = SMAXVisualizer(env, state_seq)\\nani = animation.FuncAnimation(\\n    viz.fig,\\n    viz.update,\\n    frames=len(viz.state_seq),\\n    blit=False,\\n    interval=viz.interval,\\n)\\n\\nfrom IPython.display import HTML\\nHTML(ani.to_html5_video())\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}