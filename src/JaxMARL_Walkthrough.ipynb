{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# JaxMARL Example Usage\n",
        "\n",
        "Welcome to a walkthrough of the JaxMARL repo. We include several popular MARL environemnts and algorithms, allowing you to easily evaluate your new approach! This colab will showcase our API, the speed of our environments and how to train over multiple seeds.\n",
        "\n",
        "‚ö†Ô∏è Ensure you select a GPU from `Runtime > Change runtime type` ‚ö†Ô∏è"
      ],
      "metadata": {
        "id": "BjRnlRuH1654"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies üìö\n",
        "\n",
        "We install JAX for use with a GPU, there is rather a lot to download so this may take a second or two.\n"
      ],
      "metadata": {
        "id": "R_qy-SX12H5_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJIaqAt40_rg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5715f3b-2ab0-4bd8-f468-b94adc2667c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Requirement already satisfied: jax[cuda11_pip] in /usr/local/lib/python3.10/dist-packages (0.4.23)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax[cuda11_pip]) (1.11.4)\n",
            "Collecting jaxlib==0.4.23+cuda11.cudnn86 (from jax[cuda11_pip])\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.23%2Bcuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl (129.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.0/129.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11>=11.11 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvcc-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11>=11.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11>=8.8 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cudnn_cu11-8.9.6.50-py3-none-manylinux1_x86_64.whl (699.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m699.9/699.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11>=10.9 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11>=11.4 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11>=11.7 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11>=2.18.3 (from jax[cuda11_pip])\n",
            "  Downloading nvidia_nccl_cu11-2.19.3-py3-none-manylinux1_x86_64.whl (135.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m135.3/135.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11 (from nvidia-cudnn-cu11>=8.8->jax[cuda11_pip])\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, jaxlib\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.23+cuda12.cudnn89\n",
            "    Uninstalling jaxlib-0.4.23+cuda12.cudnn89:\n",
            "      Successfully uninstalled jaxlib-0.4.23+cuda12.cudnn89\n",
            "Successfully installed jaxlib-0.4.23+cuda11.cudnn86 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvcc-cu11-11.8.89 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.9.6.50 nvidia-cufft-cu11-10.9.0.58 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.19.3\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting jaxmarl\n",
            "  Downloading jaxmarl-0.0.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: jax>=0.4.11 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.4.23)\n",
            "Requirement already satisfied: flax>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.7.5)\n",
            "Requirement already satisfied: chex>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.1.7)\n",
            "Collecting dotmap>=1.3.30 (from jaxmarl)\n",
            "  Downloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
            "Collecting evosax>=0.1.4 (from jaxmarl)\n",
            "  Downloading evosax-0.1.5-py3-none-any.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.6/144.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distrax>=0.1.3 (from jaxmarl)\n",
            "  Downloading distrax-0.1.5-py3-none-any.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=6.2.0 (from matplotlib)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brax>=0.9 (from jaxmarl)\n",
            "  Downloading brax-0.9.4-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnax>=0.0.6 (from jaxmarl)\n",
            "  Downloading gymnax-0.0.6-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m92.4/92.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.7.1 (from jaxmarl)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting wandb (from jaxmarl)\n",
            "  Downloading wandb-0.16.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.3.2 (from jaxmarl)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf>=2.3.0 (from jaxmarl)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.4.1)\n",
            "Requirement already satisfied: optax>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from jaxmarl) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (1.4.0)\n",
            "Collecting dm-env (from brax>=0.9->jaxmarl)\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (1.6.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (2.2.5)\n",
            "Collecting flask-cors (from brax>=0.9->jaxmarl)\n",
            "  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (1.60.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (0.25.2)\n",
            "Requirement already satisfied: jaxlib>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (0.4.23+cuda11.cudnn86)\n",
            "Collecting jaxopt (from brax>=0.9->jaxmarl)\n",
            "  Downloading jaxopt-0.8.3-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (3.1.3)\n",
            "Collecting ml-collections (from brax>=0.9->jaxmarl)\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mujoco (from brax>=0.9->jaxmarl)\n",
            "  Downloading mujoco-3.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mujoco-mjx (from brax>=0.9->jaxmarl)\n",
            "  Downloading mujoco_mjx-3.1.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytinyrenderer (from brax>=0.9->jaxmarl)\n",
            "  Downloading pytinyrenderer-0.0.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from brax>=0.9->jaxmarl) (1.11.4)\n",
            "Collecting tensorboardX (from brax>=0.9->jaxmarl)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trimesh (from brax>=0.9->jaxmarl)\n",
            "  Downloading trimesh-4.1.0-py3-none-any.whl (689 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m690.0/690.0 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->jaxmarl) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.7->jaxmarl) (0.12.0)\n",
            "Collecting chex>=0.1.7 (from jaxmarl)\n",
            "  Downloading chex-0.1.85-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.1/95.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-probability>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from distrax>=0.1.3->jaxmarl) (0.22.0)\n",
            "Collecting numpy>=1.20 (from matplotlib)\n",
            "  Downloading numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from evosax>=0.1.4->jaxmarl) (6.0.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->jaxmarl) (1.0.7)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->jaxmarl) (0.4.4)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->jaxmarl) (0.1.45)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax>=0.7.2->jaxmarl) (13.7.0)\n",
            "Collecting gym (from brax>=0.9->jaxmarl)\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->jaxmarl)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.11->jaxmarl) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.11->jaxmarl) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->jaxmarl)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->jaxmarl)\n",
            "  Downloading sentry_sdk-1.39.2-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->jaxmarl)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->jaxmarl)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->jaxmarl) (3.20.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->jaxmarl)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->brax>=0.9->jaxmarl) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->brax>=0.9->jaxmarl) (0.0.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->jaxmarl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->jaxmarl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->jaxmarl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->jaxmarl) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->jaxmarl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax>=0.7.2->jaxmarl) (2.16.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.3->jaxmarl) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability>=0.15.0->distrax>=0.1.3->jaxmarl) (0.5.4)\n",
            "INFO: pip is looking at multiple versions of tensorflow-probability to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-probability>=0.15.0 (from distrax>=0.1.3->jaxmarl)\n",
            "  Downloading tensorflow_probability-0.23.0-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->brax>=0.9->jaxmarl) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->brax>=0.9->jaxmarl) (2.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->brax>=0.9->jaxmarl) (2.1.4)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections->brax>=0.9->jaxmarl) (21.6.0)\n",
            "Collecting glfw (from mujoco->brax>=0.9->jaxmarl)\n",
            "  Downloading glfw-2.6.5-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco->brax>=0.9->jaxmarl) (3.1.7)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax>=0.7.2->jaxmarl) (1.6.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->jaxmarl)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.7.2->jaxmarl) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils->brax>=0.9->jaxmarl) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils->brax>=0.9->jaxmarl) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils->brax>=0.9->jaxmarl) (3.17.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, gym, ml-collections\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=7b4c2e32b904ff9e57139810ebd0c46b601a191b6b059fb07f840fb440193a12\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827621 sha256=053fc95b3ab5c024bbe0999a116ff13fb47273c81d564ffdd45d4e3717f0af7d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94505 sha256=914736aff2235e48d072ae562ba0be0bb14868513eb91917ca7ec722e4d8a81e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "Successfully built antlr4-python3-runtime gym ml-collections\n",
            "Installing collected packages: pytinyrenderer, glfw, dotmap, antlr4-python3-runtime, typing-extensions, smmap, setproctitle, sentry-sdk, pillow, omegaconf, numpy, ml-collections, docker-pycreds, trimesh, tensorflow-probability, tensorboardX, hydra-core, gym, gitdb, dm-env, GitPython, flask-cors, wandb, mujoco, jaxopt, chex, mujoco-mjx, distrax, gymnax, evosax, brax, jaxmarl\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.22.0\n",
            "    Uninstalling tensorflow-probability-0.22.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.22.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: chex\n",
            "    Found existing installation: chex 0.1.7\n",
            "    Uninstalling chex-0.1.7:\n",
            "      Successfully uninstalled chex-0.1.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.41 antlr4-python3-runtime-4.9.3 brax-0.9.4 chex-0.1.85 distrax-0.1.5 dm-env-1.6 docker-pycreds-0.4.0 dotmap-1.3.30 evosax-0.1.5 flask-cors-4.0.0 gitdb-4.0.11 glfw-2.6.5 gym-0.26.2 gymnax-0.0.6 hydra-core-1.3.2 jaxmarl-0.0.2 jaxopt-0.8.3 ml-collections-0.1.1 mujoco-3.1.1 mujoco-mjx-3.1.1 numpy-1.26.3 omegaconf-2.3.0 pillow-10.2.0 pytinyrenderer-0.0.14 sentry-sdk-1.39.2 setproctitle-1.3.3 smmap-5.0.1 tensorboardX-2.6.2.2 tensorflow-probability-0.23.0 trimesh-4.1.0 typing-extensions-4.9.0 wandb-0.16.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install --upgrade \"jax[cuda11_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "!pip install matplotlib jaxmarl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: JaxMARL API üïπÔ∏è\n",
        "\n",
        "Our API is inspired by [PettingZoo](https://github.com/Farama-Foundation/PettingZoo) and [Gymnax](https://github.com/RobertTLange/gymnax), making it familiar to MARL researchers. Below, an MPE scenario is instatiated from JaxMARL's registry and a trajectory is sampled using random actions. We then visualise the results. Examples for more JaxMARL environments can be found [here](https://github.com/FLAIROx/JaxMARL/tree/main/jaxmarl/tutorials).\n",
        "\n",
        "* `actions`, `obs`, `rewards`, `dones` are dictionaries keyed by agent name, this allows for differing action and observation spaces. As agents can terminate asychronously, `dones` contains a special `\"__all__\"` which signifies whether an episode has terminated.\n",
        "* `state` represents the internal state of the environment and contains all the information needed to transistion the environment given a set of actions. These variables are not held within the environment class due to JAX transformations requiring pure functions.\n",
        "* `info` is a dictionary containing pertinent information, the exact content varies environment to environment.\n"
      ],
      "metadata": {
        "id": "uOaiuWkePf7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "import jax\n",
        "from jaxmarl import make\n",
        "from jaxmarl.environments.mpe import MPEVisualizer\n",
        "\n",
        "# Parameters + random keys\n",
        "max_steps = 25\n",
        "key = jax.random.PRNGKey(0)\n",
        "key, key_r, key_a = jax.random.split(key, 3)\n",
        "\n",
        "# Instantiate environment\n",
        "env = make('MPE_simple_reference_v3')\n",
        "obs, state = env.reset(key_r)\n",
        "print('list of agents in environment', env.agents)\n",
        "\n",
        "# Sample random actions\n",
        "key_a = jax.random.split(key_a, env.num_agents)\n",
        "actions = {agent: env.action_space(agent).sample(key_a[i]) for i, agent in enumerate(env.agents)}\n",
        "print('example action dict', actions)\n",
        "\n",
        "# Collect trajectory\n",
        "state_seq = []\n",
        "for _ in range(max_steps):\n",
        "    state_seq.append(state)\n",
        "    # Iterate random keys and sample actions\n",
        "    key, key_s, key_a = jax.random.split(key, 3)\n",
        "    key_a = jax.random.split(key_a, env.num_agents)\n",
        "    actions = {agent: env.action_space(agent).sample(key_a[i]) for i, agent in enumerate(env.agents)}\n",
        "\n",
        "    # Step environment\n",
        "    obs, state, rewards, dones, infos = env.step(key_s, state, actions)\n",
        "\n",
        "# Visualise\n",
        "viz = MPEVisualizer(env, state_seq)\n",
        "ani = animation.FuncAnimation(\n",
        "    viz.fig,\n",
        "    viz.update,\n",
        "    frames=len(viz.state_seq),\n",
        "    blit=False,\n",
        "    interval=viz.interval,\n",
        ")\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_html5_video())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h3VkMmsdPfc0",
        "outputId": "ca7f3e9b-9394-4ff8-fb1f-59868e11699c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list of agents in environment ['agent_0', 'agent_1']\n",
            "example action dict {'agent_0': Array(40, dtype=int32), 'agent_1': Array(37, dtype=int32)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return lax_numpy.astype(arr, dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/numpy/array_methods.py:66: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return lax_numpy.astype(arr, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comm active?  True\n",
            "comm idx [0 1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"500\" height=\"500\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAANcptZGF0AAACrgYF//+q\n",
              "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MyByMzA2MCA1ZGI2YWE2IC0gSC4yNjQvTVBF\n",
              "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMSAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
              "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
              "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
              "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
              "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMg\n",
              "bG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRl\n",
              "cmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJf\n",
              "cHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9\n",
              "MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3Jl\n",
              "ZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAu\n",
              "NjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAc\n",
              "m2WIhAAR//73iB8yy2n5OtdyEeetLq0fUO5GcV6kvf4gAAADAAAEdRzR55qyO2y7AAAFnABDAP/V\n",
              "+jn/mANQmRxsfOcxuJNQ2HE4tXAlX35AeljsMFCejAOlVB11VjiX5okHqg2rgZXLgere9joI6d8O\n",
              "faF4Wb29k+Qkv9/JQ6xHGs86eU9ineDsx04V0XatQrKk48npG9YJ2wH+QRnhHATf3KAB4Zj3D3oZ\n",
              "xrJ2O+H+scE8MLbN9lNXTt1DoBfn5cJNkyj45+G8dOBUoMTr1jUP2Q3REJzGUBLAlNysqnY8Ruen\n",
              "ebOD8BEhgMKKKsh8h8zrLBFhOYmbsqCJH+JTetieDQ0GS/5Vn9uVliQtYmrxwXpx988udRCWoxTJ\n",
              "YYVlAnGLeiNXp4Sfd69TPaPuythiJyD2xsM69Le9CpjpV4X5w4y8mYYt/yndBkgH9t52aF9cJubl\n",
              "8g8W8qZ+1th3entgeS+DNlyDZNFZiPRSASTgj/swDMKnkZA/lBaD7sws+J/srrhodjlR9eZgh12B\n",
              "1msUs/C4cGoNiL8cndyztzdC9Ezfjo0wQMUPpKEuuXeR+AsvzGZ/3biw9O2CzuGT23z6K00ig9gl\n",
              "5NHWU7wFMvW11epU4J3IGvrgbrVoVgaCrgvtoIekzb450grFfumyEcM7s32iMdTAPmBigx3DCOGh\n",
              "CzrPDUIk2SAOCEsgVqGOiivhxnHnYoGhCDXJqX5vMjdmEehZOeivWwbdscnBPFTb9ZTKFmUkq9qN\n",
              "XrCbC5ZLh16oj7eDZVCSA6v3y41BWnDJTBfSYYM/HfbyzrTLkpmVVxS5BAER4hTBS3NUuocX6lhw\n",
              "Ld2+r4NfDvHVvX/14wIoiIQf7OG4jYBYGI7ABYCujd430W62tM3iifkAiKVvcAkwWC7yUkxPj98F\n",
              "yluPF9rZ747euc/Q5Ivv9/snng9XnXlYZWJVj3byAW7NkwJGgZjAmApDxHUUoMfb2EA5SqUyAU8X\n",
              "jP9QF6tp8rfP8G0wcwOGzbSfhOdrCAdC+9GjZs1kLgq/pdrADQ2tBmUmfM4TBHjhuB8BU2M8f6DJ\n",
              "22KwKQlUrV1VdbmdA3a+jGSyxi76GsqnuDtm9axkM1Ur7M21FOJu/YXw7x/+u7F79ACQlc1fxZKD\n",
              "A+zI78U6aQtg3uU8vXzVdMefR8kdqLXe8rVvVs4/NWo5f/22TrnBCZejqsrXVwZRzZ6tJlpMQdNe\n",
              "YFe3GtFAFIMMyU7i36oEHyaI2dIgGMJvaGsALrsyq6h6r2ZTgulZA+orApQpGVXWgXYCKBNfUVtL\n",
              "iYK6GtiZLsLQiU1VdbZ0xu17GcyqvwIA8EE6ZqSVF4AJ9lDpOY3KSv8nIxrgzRY7mOX0BfmR+zau\n",
              "y3mgb1Mlb2/idEaS3XwKWT1azU7E+BWjTnB8//bWrx3RFzhPjoa9UFp8v8eZN8gf+rLQUYt6DEkG\n",
              "fQ+ehFPjil9hi0AnPeZqq3IOLmE5pTBalxP0C/GLjlQSow6ibjqNKKhlIyveeYnXuimPipqoJZxP\n",
              "SeM8QoZyEc4+DiGbupt5rsa20x/+fyp41U0oJgrx7BzPhxcOdbIM+S02S+Rak81Fy4DFnf2kHSsm\n",
              "+fTdk4cVUyZtJe2qm1IgDfDisjZJIaFuA8Spj/duFsGiKAuZ8Up1aFEkIF1jo7sAEaGDcymhC8JB\n",
              "DcZlU+JGwOZ1dtXUhSdYHCX8RjPGwPodW6fGT1cBIZHKmVvm25FHgjxl9TKLZExZywz7pjF4VTPk\n",
              "ujkMn/0Niwr3SA+JyF2uUlINEPCDmnxQMBqI9ZUFpv7y8FHZcbU3TOmNCX31c8H5KMXXjeq0Ygg4\n",
              "S0Z/gAqQ+lC9pA9EXvx07WM9PcUv8VyJhB31+US08tK/EUhcV/iv1VO1W2bvR6HYS/VH5UgHrTJu\n",
              "V1X/X/Y7d97DD5UnR2JHfI3v9jaX6iA3ACskppBuy6quBurVhG/mxnZTMwiCGYxkS8b8PvH9o3eu\n",
              "tcGAuTUJy/twtjv9ERiIJqq/RxQDJSecB6E52BpjZlZjfpQnrgQ8sDPOghrwJU5hCG/rVDXtoEJ7\n",
              "GHjX5cdYWQQaVD8qurn0S0z4/r1JaYgwLyW06w4IYTVc4/1uTxk73Tm4BOyccHk0TOxdp8vrvOj6\n",
              "6bxUOQFnqvRlXFPKaKjJRUCwjtZ/2VCKImc1uhBLbpQUe84Kqu+Vtem5XuXxvR1ZDiVRg014Zh2x\n",
              "C20ZZP8HIy9OxSctP0gY3cE3jxwxLWozUnFx568EYInn+QRzE74hGJrrJKgmZwIL5gD2YAoGQleF\n",
              "vMdXCn3I8qJm3L1m0rPpUSmaS7o6bB5UWpG05Z6QXYgIBswQSDsb3j/X+Gar7dPuuZ3Qvzav03+2\n",
              "0cxDKuyMK8DPuXB8M1mcXw9p73oQOyZks6NRpz57xgyTy8G21cYx1OMT1DfuM5BMExiFBaxlmXB6\n",
              "l8oR/m+LIkjLlId2a68GeSVXUDOV13U+T7yCVluOd2wiVA80WXRwjNmN4ucnCxE5RFvVcUa41lDo\n",
              "lIQ6qGNAfrG5LcrWYE0boYGrvMPemU3oFCjzcIE6d88KRYMmx9TTtU+X6Or1qz7ax0TfIWH28Tv/\n",
              "JKutGkT4tHj2qfkIkYrSC+iJDPgrGgWqWzX7+arN7iPJ+refq+zxgtv7ARH8KLcuK0El3HPP+UPf\n",
              "DiSEMej/h4C5/nk2/Dd7XwM0hL+qO1k62udLxroaZrWZ48wLt4v7jOWIp9ATHWho/VfKWzArXCsV\n",
              "fw1t3QNaGOSEdzeid5JAQg4aZ4+H9+6zkP5T/jiZs042mN/JTYzKuLoEgKBdIS4DpvHOS2R2SlL/\n",
              "vl/nMYXn7ppywRNtJE3rguXJXlduY+Kfekt/GRWFD2Mqv+pnKNiZViHTppZ0doKC9jrDImESN/XQ\n",
              "v+njINoCyazymBAFDNIOepm21b5QpYX62DQ7qla1uuq3jB/Lu6+Ycxf/W1gO9eaKUuQVxTMtI1Dr\n",
              "xP7ZrwpgVvlt4dZmcb6zF0FfA92s8mFMPY5miCnDRRDgmXQXaTJ3fkjcuHLrgILiFnDyzSPgcbSX\n",
              "EqeYc4L2yu6RQkVryNP82RNEpNgh9OnH1pRnZtcuIZtpgbxSShhzlPFguPYMPmltTcgfENEFp/bA\n",
              "iVHAVqqukseoiYNOBUEmm+xA604qkIH7gj8ANJuOBBIykqCf5XjfsIcxFBvhIvgp+gWHKReabgeS\n",
              "KhT/7enzONpJe4xPMx3DgfsiNQB9aV+m37zpI/+j1ayzTdB4WHR9q97ajhDGuybb9cv3iULc789M\n",
              "YwNNp0Am7PxGcr0pXw6dql3iuoLWsi6KX6xNjC0KghBKCf6r14o8hlQZ23vQIqzqWoMbBo2mRBeW\n",
              "Wfksw2d+PPrGmvpSY0BJCchudd3fPkhQ8l1rrfXXWq8zZ0uKg67gg1e1ULNM5GuiSzqqcgme20ZZ\n",
              "T7FQmJpKRMT9yTMS8sQEffSUQJ8ItX/vQ1TRdy9S+CTOOFLgu4TDeG2YdNixINCsBnVWGsE2jOl+\n",
              "pe4p6X4K4QqxxxIg25pTq7yJu5nG+qk2hI3OYzgNHdTFNtj36H18kBMEax5HvaaY3vVhn8kZtkMa\n",
              "y1jasLYNX86KYQWU7lxRkifkI8HzVHDt27KwKhMSzfYJe4NPEjGG0zuAfdBecVEjHtXC/oNj29Yh\n",
              "79WC+gsPaasDKsvvaBabMRvg/NMZTDmrCaWh2JTl7xsuEW0MFcv9lJjesxyCqLe8iNSvSG6zMMaK\n",
              "gKX+lf3eJ6ugDMLt7c64gTQ+Y1Rd2Fb+mlGf4UYBspba0/BO3GsA1hGmDdJupkokvv/CwN62k1QQ\n",
              "ryNh+To2NPSuui03M/AXAqehMCKtgdC3W918jpMbWk+33HXiap+N/yQbXtNcd76mcNKbA+6wFQ/X\n",
              "umhcK7qORvhGtOm4ziugX5h4d3Qcr3tSG04wn/f/0bqcNukM0c2LiAqS3hjZ9k+bzuZbB4E/OLqN\n",
              "fXL2ny4vmvZT9EjAFA7/IGp5HW+KFE33mSw9WqHXJzh/poWY8ZAe5UFwiDmqXtlcR70sn75D7W0s\n",
              "Xmloz1qij9KJCHzndHkG8aNT+b3Ap+XQ+BxNp7vOR27stiY+8H3KfB5iliZcBAb67p+6jxKtG/Qk\n",
              "607L+Cg+Rzh8ugcRZ0qSQeKdMwbTGRs5H43iZVP3uHEB+bdnEIsc522Q7yjpNwbtOhCRDfEAthy1\n",
              "b7uyT/RsFkon35pZ45QC1Ax/OMcZ4bDlEqao3ZLIrhMOB2bGAit+Vgz90v1LNtr0xauSFPZCq+F6\n",
              "NmVA9Mxz8ehNYFXLnZjxxg3g7JZwANqH6MkaBi4aMMixURCrtRaro1geKD/cYqRnF58rWph8gjDJ\n",
              "2JwV//VFTS/Kb8MUfkQVF+e8kvAkd2ivE9aD2lMzKCioaQTQcheo+pRP5VoxTz4xrJWm2N2aO0eI\n",
              "SALw0xdxRMeGsB5wmgsnlFh5w46Dr/KPPyXNg5JkJAuA+qHQ4XVwpjUPDN3AExAnYI6IbOm+7Ymj\n",
              "tl1mxnnX0ekMfplkIHWPR7QPaUYoMD8t6NiLutLYKyZFfnzZNHc34iqiH9kZNGjjlZTRJcEpjVCV\n",
              "7mH+ozyx8KQFnMVH5OllfzaHXbzvHEO+flIUXofCveiC1CP2NtvT/wi4JGAI5kiuQCQ04Vsv1/RM\n",
              "rzcJN/xRFFcYSmVjW5vtF/4nGTU1VeGccFxKmSF5HqGhSrfcYs5awWOTGe/+fyvchgJY7O+tIUEu\n",
              "l7WNQl6fdKZzdFWWtKEygmhOJ3JytFxWbglGklFh38LgvZ43gIsnvXYaChny+q0bHGn5L31m9EPT\n",
              "lZI2bFTODzX8BtUbjzDHXKQ8aqIOtq135pHQYWU4VgnxGJt9ar/wH9sDtUiMxJ89xcE/h2tT3chK\n",
              "lGD9TXi1aL87zVGVs+i8k/5rsMpGNzTn9wRUgOn2H36CXzze9XB6S5LVZZRvlbC+Hi4Irp4o3jlW\n",
              "Yxj+mVG9XSE48IAuvBsCDsbIGBXfnjKuTemcIUETbRvYKc99w/qH+hCqSKSLx/dzfJjNkXkf3q2g\n",
              "La2DEHSH7pp83Fu1kpl5/3avSysMuQc0ThE3ioqRehsUEiCC+9k5yCK6N+tDZ66dyStXKbM108dc\n",
              "sLEx2n1FTsbXD5mlTTPRT8bNjR9F32V8MoR/8+SAopUfmof47FY/3wtiorCFHtiClRE9OMqK9hR8\n",
              "zwL5ZLCOR090Wcl+WW/x2k2HKsjM39gyRkA50hokKDp2VtHrajHQh8fkTqiCjgmm9aC+Zl7lqiBk\n",
              "uWILGle/Q5FmdxCj4aoRJ3RgyKXU6b6Ubuh0gQdJsD9GjInbatewG8fIbCttyrbMUCEaGItWmMKy\n",
              "vsIDSYd1pd2jh6+NdskLFXKQ/yxM+RPGFJ6YHc2rAxGaw6Y+OELzIeCDfV/6rsN8XEC5f6ERg8rv\n",
              "oTJ2FMmOHVIq97u5ouPVnOru71vF7UHRzspv1BGF9zEVrPgGDVpCFel0feK8nX7FEz3tu0+cLE4Q\n",
              "SqePKJ8Phycis0kOgkgZjmG0cpVTP1U6vfDJNKaPI5Lkh0JR9WUx0irLZTiPIDEvFUm1As2bu6up\n",
              "W+YvAREJvdpce1PtrqGN6/Kd216gGL4yIw1W+5DKgkVpTLnAapjPc/1BKLCsbC5HsP6q5xNp+c/u\n",
              "Z+DUBHxuCa86tBksGbM+SXZej27rWSABYol+FAnp7wWoKsgDbqgaav7q1SQMHbNLkrjK9lROhbkO\n",
              "2ku8IKOg/T33X2mgGG7wQNYi22zdAL+3xHtU2rSVsAcS9JRJ6BCw9//x8KhNB5gExFYMyF4cul0z\n",
              "v4sGjBL3Ttx4yfHhA2aLCaNWxhzayJBnLY8K3X6ejUjM7vTwG0+gKSl0NoPI/6iaHiVjKWN339zz\n",
              "DRvqYtqeQETvDgZEmv17niaMbggvm+0XXVkF/O3p9G8lzztd8qGwO+fQHRr8ED9zr5Rj2vgRvqWO\n",
              "NipYZDWBVtFzK4uwTFPEA+nPIN2IMePOMXYiZZuNb5teudyo5TDKKtZb7JSh/ZkLAOuGagtASyH5\n",
              "XDk+8f2eQFKQiHoZZX7IKIUiT73J2xpW/3llkYbkErRoxFWfVvPNopnKlSuwsureb+Ttk9/+pkUg\n",
              "AYxc7UjYXsfFL7+BjQcNEwF20prFEKJSccO1lw4+yVw6M6mXb9YsGG6kxX76f+bvDR8o6G2JuLkm\n",
              "8MtYH98uAju60R+4t8K7oLXD9TKN+rd6U9GFw8uihaw7P1K3lKQK+AT5ufPp7G22MC+D4MezbKG9\n",
              "anf/sqGyQQUFaSi60L2ZoyGi3NByfzpSAvi4HFWfwalHZIpwAWH/sqp63MLJ+/0tDdTqSNNcBnk7\n",
              "+LKZEFpcS4Oy9MRDaoWFP92TLdWrzD0pkUJBTN2b8ZViAHQOqTE0ljgmOZrvAGbac99zA/xyRlKa\n",
              "zitAKGkaljY768yRcQW8YYj4yl5CRRsSoRr94R7EvspC6ocSxfq2/qtWmIJpk0aBgYG8ei5/2js2\n",
              "sTHGrngCA32p0REmMTHgnrgmvh6eXaJtAXUfztusVjetRcQC7bXjRz9l2cGeSUYbmIZvpw5WEdo0\n",
              "17EOAMCmY40Kq/35U+HIcs4BUfrzfXnqHyO6ISS3+RLyTOG4r0tAHpmnCgfGwaz7BmowoYPzi49k\n",
              "UyXX5Ar3dgFlqVfEvMO9Z0PHNc5eO99PU+2uoS1F+XFgKmWhtGuKXSADfVUAkVpTLohmLFVPVBqf\n",
              "mduUveGLwvbSn6lfpGZ89xfp5y6/JsM4lQRZHdAnZZRc2j6HJua49lcnmX3mw/qqrwRg2oK3QXQ+\n",
              "duskEqaP/w1zoeVgO0wf6I15aACncoRcN89I6k3nuFHqrx1Ms0jHf2Fxmxp7P//XK52YCd5UblEH\n",
              "xHXInQ1lPABrIz4oHH22lIMgTRFhe/oTKyHQnQqaKVMKuvvuBLpQvS4aU0+8hmGQOwNB3lpH0pSE\n",
              "4WbY9bN5dIErvczQCnXcpHJwe3Rvv+pCK/kdu9+b6pDtjG0WQYMqH3pUTcdzKGshk/KQOYd5xb+c\n",
              "F3nqttqRdw5TvCZsIVqPmAmNyGMyGO0a7K/uQbob1cQlKQvlIJ3aUNFPJgDDQLSrjRk5+bdhVwh8\n",
              "hJ0TFQa2cQ8YA9JlFy5MKLeYZWL4zq27DBOVWs+8BQcj/0wYZS3grQMYjo/9q9ophV1ev0tR0wVQ\n",
              "WA/l8bVbAuxf/be9whfLPi4CFTWjirnonv3o34x04jd6M0ABzKFHYDgJfXqPvC1FPfVNeFfXKM0b\n",
              "dnWVKJ3n9pt0/Niwb4Ny8VO3Ips6GrVXgHeSFAnaX/BV4aXhoygfQoXtu73tp2/W76VxMp88Or4L\n",
              "kIlm2AooUi0XCRM5NioDJTRFQpOhF4C/mhJXNhpTXOyfDtLr6IAGnZ43ZnXJHR8BCHZu7e+eZBIN\n",
              "e8/gNBpbr4y6vYnKcMV8KTpLHZ8/wpOgncrpEPBbvWenFMYpdVir5Vk7Fds2+DoDk7ZJQgjBKp6+\n",
              "eNeQOouWT3f2ptZSz5EW5bPO/epxgJdm9fyehgj/TqdLuuT4iHiShlUK9xpEqkjh1QCDEppOzaJL\n",
              "rQzMF6Xd8HA2N1pwoFzjPxALD/HhbkJuCgOzH4zhfx9UEsAMNCCXrD+GSsOQJe083rrPpqogvSLD\n",
              "lgZFMhKiUIMqC2yHhov//AlQoY6rd0zxDo6iyrTetS0Mtf7Vgf7RGAFVZUnN0fCj7mxFpyltzofW\n",
              "20Q4NSrJWkOboDQMV4388C7aAVIYoMGdclbOP+s1HyPh7iLcVs0bGdYCQnpuZQBlxCSX20+cGiVM\n",
              "a3NM8zEoF+XEv0Xo5FAj+f/lwM9TPr3KBjv6c7sPtHowF56oM8w0eawNPWVGg2jDJBBz/p1N+naE\n",
              "d6hS/br/VdwXoSXz2D/PTV84Sjpx3eoKj0HqfOJuMjFaXEbfyiJr2WjVDO2hNel7ahayEmpqvQs9\n",
              "L98M91cJNfb3bPTUhpdadScr/VcUdZ9LcRIdRhbrcpm6lVLSNBdz5bm6WkpFJDn1nt/uwq44lAlQ\n",
              "JZZrhKjs3I0GS+mv6jgE1sOH7IMClXpaXS/MQmV4Ih2e1V8OLu4otYZFm5QuePvml3veIgknCv75\n",
              "fft0cGPfrWWnvSpydL/wVWniel7O2k7ZCy7zRALfAixnqv+ECLgby/9ck9ZeProbsQjzjUxV0V0A\n",
              "ink4JaNwu50Rddwr7u1Q33iRYi7YvL/zuGbqAstRhdVFVdl25FZFQSE6opWeyIAdQKxmYzpTuYif\n",
              "eWMLP71O7dnHEBs7gftpWa90NQCGBna1+oI7+25nm2fkZdrDYb9CLul7QowZR6AgixS29nFt7jhu\n",
              "TD8/bnamZKDIiqHMLes/xzKzNxmRMbGaURHbStMrn6Sc24MaXaAO9lhjLWY2gjNU8G1J9CelLqd8\n",
              "6uDAdYS4k4zpthBlhszDfShrf5vLJ6CcJAYNZZb2mPOATdda+3l6QOIR1da80VXbw58UBF9XJhr5\n",
              "fjJqNPFUDVRbwFLYvN7Fpmf7sUSCnWtVUTHVuqVhCXGYBj/MtHHwaaNQv7W7zY8xKjAvixh9Gz3z\n",
              "2/jJdARttQlsqIO6EYF9MFWrkn4zmOd+TIYHsmJC2qvlHQYoKzgd0SbHbDT4Jrdc6jV2VtFekODP\n",
              "p9lngLmhdQCRSkOy5fyFQgNd7JqReMSsOVcAK9Kw3kvnO+Z2+Vh14jkWQjnDqsxTVv0JQvK50X3e\n",
              "SRiGhwydCwBHUyEK3BKoZNg8K1N4FsSndUmfxKPmjI6lCKm5bilsE2KR1mWB76n/0+R5yrPeYW40\n",
              "q/mN5CSgL/20yag+uVHr1FTBj+NO9AKyoWwLjuVd+BkNp1nOsZrtEKFEQ6NPCqzDEiwZ5TiUTw/R\n",
              "NCwEHI/aauE0b/ma/K9nQkKvsMEejrkumHZHRn3Xuw/iQUcRRApO+PbGoxQLbla1o27Tcp08e3Kg\n",
              "cUTaYJw7jxiERCyFJcIhVuDhwHzsZiKETvsZpyc7KPh+pNU/LfOLB0PlXshf2BarxvplrFVPpPIE\n",
              "5nwX/TjuDUfXXNNZGDkE1S4X9HsxOs9UpEI4qztkS9wRN8wMBA1ncmxcDKU30IW8RvCfTGWfdSsi\n",
              "gc7gC0i2FdFARS0oMwNjNbszBx2Bldjy7ECtppsfYhNETxFrIS9Rbl4Glui24JbgZA3mQNpH+/eq\n",
              "bbTt58vocvADGIYpPk0MZkd4MyTLQcl1ybmGiRfl5VqLhHnuHBu9MGrKEvl92fVEFlKLWQl5ZlPV\n",
              "aDmf+WHA2bzoUYFTLim761frNl1+NterkVAkAZ81to27/v9wdK0XN3V9WiLYYRhEYQKYH0rk+GiY\n",
              "4TKyIdsPqvmTtDwgbOEUPpDshi8cPwFrFy7jAh6PLOezvQZb8qDAYt9dJDDxGHtcX/BXjkUli8lD\n",
              "DykTQN/Ix006gpireo9lbdqbHYxQYsIYN8yAT4SjZuOMidbJEGgUPCUoWQVOh/lMxOiL/qyUwD5P\n",
              "XXpU4LbE98chB1Z4uPDC2dGtryqxiWy+b2gumfqHuymIZpeX5yBJ8yQQsRjbGGQmlwZRfY/qV+Hk\n",
              "nkM2zjLvGfpcass2XwW9KyR3qm09XHheu8aCdwxSB/BqZqccTz1fki8d+q7K/XhC+M9F3mrVCVGf\n",
              "iKKuVEw1V4LWctg1UeWvD4T5K4Vu//WOB1gYAhhEeQ+BFbVjjt8AAcOzy/RvwzL1oZNk3pS1mOx0\n",
              "kcjDhE422OOVrc471X8Ip1py8bBsK4BRmVrbtXNPBNF07sVwGkOLEOwtf50x6NTCeFP+2qSq5mGy\n",
              "zp3jjutUJqA5ndYTSfYHsgzpDQn4JWHDAAAXMQAAAYJBmiNsQR/+tSqAA+bjXgBFGRuD/wK+2Z2i\n",
              "Cg9otgZHRkhgamv3MIdrKQWlnKpjYBSXHyTwxAFoukyf7Zke88GmaKzcqQyazUXDTtaU61XxT5W/\n",
              "i3Y/+Ouw/2l7S4MH1lK7JmFOn1dDUYg/pEXP0uitxyGaCJr/2zOrMR5IRGi5+yFDeOzmyLL4aE0Y\n",
              "zHjIWIvbuXC90XSsK2PqyneXzFcGPvEeJNH0ZfRFUlw7oM3SG2LTi3eTJkBE4dkLOZbilBxtuBQh\n",
              "gOpNAkzaM+ZhOBFQ5A+4hx+foK5v9mZv6ppWhuI4eCmpNEfT1zlBgyO8lCHD1NsYaA1mQthRaHrS\n",
              "mAFR2p1nwi0QN8YqzvILWzkxdsf2DQjhACw9kCdpLazRuIsQLgIzt9FbZ/vg/q6Wkhq3nsFVWKzc\n",
              "29AIpsiHk3amjsNkkAfPoHLaKWzjMzGHZ4B0Qg66rO2ZIWqvu1Zw3xN6ThYpmJW/BFM0nURzrjg7\n",
              "A5ENkXRo47uhrLlb2BQ3UarZgAAAAKdBnkF4hv8AFiVdoAFyggwbyY0ozoqf7N+KGtrHo4Gd7qBo\n",
              "Cu+JLpPlMxwxmCLhI4JEP8Z1rkazw/zJ5JPToEm6TIt344c5EC/lLBEk9wTcm9QDGVqwY/fBifSq\n",
              "ac0Jt7CVOK8rNt933RMHbLabeSAduO2n3RJcfKz629nHVZ2LkYvKNAnJSWfqdyDkIJ4WjXjYrq+5\n",
              "wcdmH3cOt9UWvmdjsHhJ4YD0gQAAAMEBnmJqQ38AFifI3ACDE9/tuypDtTqzVqpLZEkw9pWTBl1N\n",
              "xlKjP+ozXH2e7918u8BjplcdSab3FnQ0tAcQS3dskmSRiiBTOED0XyEHxGhvtxDwyAZgqwRPBVeC\n",
              "cgs2gs/6AKxu7FFCN1/OUZsZZQZ9oH+36dqziXTs12PC8KPNbw9EcQkDQx39SO8xR0zf1m59oAfB\n",
              "FBRnegFfoHKltBFe/qkKJPuxUlb12M+xFpga/jz1/xAiW4ifAnbUTOof8vY0AAABKEGaZ0moQWiZ\n",
              "TAgj//61KoAD5mnIwBFGRuffMjdIqiSMOvuL8QfmGBaQJm3mj4ShzgnHBn4tbzjIn31CshtCATIq\n",
              "A0MoT/VbVoxOXcAvmzerIjY7n/wToVH5DUZaj9cXG+BPw0lgWAIOkCv2tffbLuM/B2+gtFroNCs4\n",
              "ogU6r3RM8Qf88c1EB7MB3zvQoyLnkJoViJ9CHZxY+0wq6Dy7Q9ES4PkIA12JkCfyspucpl29y+Bj\n",
              "chGZrbKyeUTFFJjaBQJT+N4xU4s+sdrS8OyUHVSfK+5fH1tSS1uVd3rzRTcflkY2mD1UgO5M55+Q\n",
              "tJEuXbSyODv3Z/HkLh51rsNZWwlG2DsOR3OYuhMDYXJBfzCjukvgEwg61ZBbv7CSd3xah4ZaQ84C\n",
              "/T7hAAAA0kGehUURLDv/AA9IEMWAFrvlYfhzU3V0Rd0C/HenbEEzZ9rQjm8cTYZ9oVbec5wsm3FU\n",
              "qAI/9Zi7GIfv26rmLOjsd/dkypXXxGdC+BoiDRQSDXdg+nnh2CRff0QVmH8TiEaLMcUiqFRHLspi\n",
              "8tntHhCSVdAq47WR14RI4fUfnj28Pv1Ygu4OVzSuwuESd+caOt67qZM6lSqe0aDhkDpQtJ/Oft3v\n",
              "xpVkEwrZNGO9d3yxhCUedhzj7omb1PyHoIeo0tc9YP5ZN3bJytVmXyavDDTGgQAAAJcBnqR0Q38A\n",
              "Fd3umOchAXztAB86Gv994iZ1N3VRGOfUV6OZztqqETYThp/drgou3oq6rYEexRumSe4C6Nh60FYX\n",
              "Z5dvDYrUKFPxdHMOotwq2kpWNrfaZjn2fmqBI8unMEq6MEP5cpLMFnqm3MGu8ajCuX+g5ERD5RB2\n",
              "ATwgx0qzbYOvcBvkoH3JIW1eY75f4TRj8XYi7dg5AAAA1AGepmpDfwAV3caSMMLlhQAIbKCM3Ucc\n",
              "ngILQHmOgmZW4BIz0rzi6ge4WfQA30qGUl5x/nyXfMfox86hZI/5ArPL9748Xbz3WyHALfKujYGO\n",
              "PcYhJBkx6ZWywS7I69SxfZ0/qTVjEN8HjwwNafD36NjwlxKOZ/wICKYN0tG5qV7c1/jZP59c496/\n",
              "cneIQCIuWh71xobZdRPHQHND9SyD+4WeFyhl0NcyPRg38zB58nEjSzoHERkTU+BTtmcprrvSh7Si\n",
              "YF0vlUpu9SdvvgeXeL4oR43pAAABgUGaq0moQWyZTAgj//61KoAD5k5Hh5rAEUaYuK2F/JzUGRQM\n",
              "MdzGbgKpD0gmcfkpsgPx6QD12XnYmwmbXh32iPIlieBkWuYxocyMHQI3/PikQG6KVBD/gRfPVoTk\n",
              "qYI4XtlwhmpBsYR9nA0n7gRyKyZORo5oOsAz9zv9kIxuzU5jqONihoHy9v1S0xsPSX/flNdzK9e9\n",
              "5aiTBi1FIVHNnsGyGSjQQYxybmhZrm1Xhe9TblnmRrtS/FzeWyt6c+WVKV+SY6qeqR6DZSiZWExq\n",
              "xSAdvifyMpjdkzCPzc3vUFjxsixF77iPp8NHzwFKFC3LZhkq78drvhkuY4rOIrgziQr2fGVV0ELZ\n",
              "iIzms7LMPbKBHcp1QiVLuCq0EJcg7tPxLTqpG4W3YKZ7R+237dME2vCImDhm8U59KDfdDN9T+Rjb\n",
              "++8NOPpz+PjhrNqAtNFR6MZN5WjK/JJNsJptduJHPM53XDVIknUq6bPQDEk186rdr835rlhg3Vfg\n",
              "unpJ39mwW0AAAACcQZ7JRRUsO/8AD0TY5pAB9osx/5bQ1k3k49kU1UTILJOdy7hQwDw8gZ+3Y3K8\n",
              "GV7sGzkRnTrz7qqCQ+n3D2yG3cWIdXDhKcqIvK/3GuP9RJjcU8njwarm4EZqo3GXTRn+Fng8zMlr\n",
              "mrke0JinLDSAQ5JbNrbL9PVIVHFqAs/Bz85AJtAEhmGmIjlwthDVHSNCUvbeD+e6d/sI/DJOAAAA\n",
              "rgGe6HRDfwAV3e5kCpMdABr7Zs9V/ljYOuCtDk5mQiSU4erZI+qyrv+oNyqvcWLGgnSjFbQusLHc\n",
              "v+zH3Mf5zpziHkUZ6LcGtohacOmN8qlBw5etrXMVUj1IPr7oO+InOf8bYETZDKq82xCt+YjAZq0J\n",
              "Ybb+8Fh59ajgZmmXr759TDuKBAwMGkTLuT1yNsorDE9Wp1gGF8Yt9r02sXskIbLgmJy3pArXmnLY\n",
              "3+FUkQAAAMEBnupqQ38AFiTTLC7j4AQWc/cx3Xn7MVob+f1BsIqW9tLiAzVs/g2M+fDOm2c/WqBg\n",
              "AvNAEXZ/c5ly9fv82LeGtRqbQc6HPROYbiaKNnOYwnCamso3ARrAQiI6VNEJUbIFhlzPA7KWmS9c\n",
              "gVXp242xBA4V1/qvBQ2z00P12ivhH088xH1msWD2VYelM5zWReXH9Af6jJVAtx74i/I83PomD00p\n",
              "DjYyONeEZJvBFee/SAgLmkTHLp5rc/jCrLdy/Fm9AAACYkGa70moQWyZTAgj//61KoAD0QuUAC9k\n",
              "HTJ5Zim78Eod4niDfr5T4HatTLKIyuar6rNCoX7qCH5np7JmisHqIuxaJLZxEYIZEDalpOSVLd85\n",
              "5DQcHhL/VWqA25FkmrIG/Js2srxFiPjBfCPc20/3xYcTWk2k9E6h5W3BN8mRLRlk/7Ft7Hn04HEv\n",
              "fbaPAYIxskVacSykbodAglub/rqwhxBbhCK9OSux3TQSEYqgE+SRsWAnNU2kdorW4MWscTNs9EXX\n",
              "RHzz3uzYwLqT/P2fFN7Kw5ipT3yqADHjL/RO0vkBmckJmUtF8k70a4M/8m3X1/P9xbwO5wa34E3H\n",
              "kd94Ii2+EI0T8TcIxW+O0JuDMgpHM6w9Sg5KDWk/WDUOgJoaB5v+qDhlpxubLWHTV4AQ6lvcw+iZ\n",
              "qTR9Z8aWdHuQjHWFmWxkrg1/JLAfsTbFLz47sgB9WprIzms5MveQUnhqHpy3ZQe1Jf/a5I2+I0kN\n",
              "TnzGX1ter91wIIYUVX55mlPceF6AxHug9Byky0lSToBj8mmLIj/09/E+AM3hTSY5MlSnbiUYU91U\n",
              "KOB/upubBX9hLRN3YTv5S2eZ4d4NKXS1gIFG5MR/vrJCtyBPTkgvP3A/gqkkVYIM+stvb4/PwE/6\n",
              "k2keROmUuxLlvY+vM7tlLVmGEqR3B80GfDm0fNwEC/shZbPS+6iZ/UqvZn+SnutHwohv+2xaguo9\n",
              "kVNf0C9VIGEUFiPZix0bOVYNVcBDN65L+YE2Yf1iUkCpSq9l9G48dXEdABUXdW60W+gpfMMuYVgx\n",
              "4yvYnutNIwhS7Z20FP/l6SAAAADSQZ8NRRUsO/8ADr6zwimVojBQAa+hGaXevuuPXD1KYwTw4fdk\n",
              "qdp8obnpZf63jCmTEK1JdAcZ6CwEqWIyO57Lv+0Df6hTpek7gYB4lMfBrSkgOaWgqsfPCZfzlvNV\n",
              "3IkXpMiDuffia2zT5/cYN747+Fy8uyNOr25dJWrDOVFgFsGJs1AJGZA4g9qCI1CQPFNNdUOuF6OC\n",
              "MlaiJt+JUGKFiqXCcjM3NXZE661CQGNsYsiityUrGb7MhBsnSSdsPlPexQYTPlYoz39Z+gX7sb5G\n",
              "IK2BAAAAoQGfLHRDfwAVSf4eewBAsAIQKLzN4CgSRlmXyoE5eun9dNbSwN5plZOrg7TPNL0dpIqt\n",
              "oeOaNWlpcTE07htUZf8Jyp31Bs0ma80OqjHtlWb8XX+W3cj0K7RhTS9Kkr/4Sk13D301LY2VjsRF\n",
              "qR5lDHf13nfgING6KfEmEenPq95Alpc8+bT4jI5qNkEQOBRW+gq0PB1utBgiaoPfeVS3blJBAAAA\n",
              "2AGfLmpDfwAVQt7XoRJxM2RTQAH8x/fuKB8Cx/IIuPc90peJ5a0oA1twMh2xvyXHMd6xaDMcFmt1\n",
              "fLSxsWRG3Es/UaFj+Qlha368jmJyQQVQzX80cJTvMdTKTiXjDQpfottHYhjKVdgGDrp79MtCcAwf\n",
              "MkycLIYwGFKvKwAoesRsY9dkX0bDPtz5+Z4V07yxRU2cidnnB9sgUrVMKv8Aq8EGmvkDPMjIEMWY\n",
              "WcTsoV1j7Sb8o2fK7Tou+adhFgLztCMwgogjOch1hEiBZfkqfiG4mynVMufMCQAAAO1BmzNJqEFs\n",
              "mUwIIf/+qlUAB6WVAiACG1Nf9kfhq8VNrCvsKaBT3wkxb4WjCVPjw5s5d3CQnPFXNNZAvrH7AaKS\n",
              "bX2e/GKJa8x+uBLZFr0N9EDVpFC3XJ0G+g3ikSI37qLeDxi4Esjch0DnL0leoPff183x9AJFsMoi\n",
              "GLoAfAZrjhUr3GJjdcEZvqMhQcfMP+llZSEQPKCl6nvoz95eyHdviiskeHAm8Zih9Rw3Qw3U6Dk3\n",
              "gVXR2uk6CvXBzwjOUEUwwQNIvi9tOo3tQvhZzonGBHsEM5IeY6uMrX+ZgaFny+e51JtFHeemI4Xl\n",
              "6SAAAAEvQZ9RRRUsO/8ADr9K+HqJhOxUADrwvVJ2CFWwkPVfi45x5I0cJYmwq/0hq5Hkw58IKZYt\n",
              "IJLY4hJVG13S2Mm66C9ANJyj6wHIbbZnHBPtnHhxhyNQBF4t071AHPdbVJ1/8IsmOaql15bS+K6A\n",
              "KKvNpsOAACzN9dXoen0JaZ2TFIS34ItKjgzOyw57pCz1N9GcNvbB++si+UzpZTS8N9Bfc3QNIbyH\n",
              "h69OzpFjwurfFD+4YOwljAKX5yHYUbMS9OnWeDc1jEWO+uHTMCxGTNZ7h+9uyzM9VghRegTWcEhw\n",
              "l8KRPcNqMhqC81PjYggaJXAev4nPU3BL5/0lnRU9usYuVXZLL+Xw9Y786FfVaxk7BsY8/wj9VTe8\n",
              "O11mtJGvvuU2oJbZPGsngxxsFV7+EuuAAAAAwgGfcHRDfwAVVZiKABDgui+wTFV4U9igY9LIR+GT\n",
              "Pt1fRKg8wvgftpu/51SluLM1rAZNzwvGsbNu2byte5it5B3ZFLjz9N8HKJ3Rx0Uy1Dk3/eqlSB3u\n",
              "uUogJCpiQEbKFxqPFIOprDdT5JnSqaonwLYSP9H6CZ6POqTpx+H7XYWXKPCIqUjl/MjCA4Y6VlIE\n",
              "cfPul68YdiNDb2qjAiO0tHmXmV6Zo5r77PRjDigA+vZqmmCfwr7OdpDLhZwwh8GT/LmfAAAArQGf\n",
              "cmpDfwAVQOvuZuEFpgA1lnVl/guCWiqw9CPn0qQkXiK3aW62CaPhHtupCzTOvS7YKiT6UnLeiCsl\n",
              "fkY3/7UQnj5wfMEeo74UQicj0V+xuzjLT/ARo3xVmRIrlkr8aIc20KqQZHC6TfjruSE0pA70FfcW\n",
              "GRFfUnI2X7ZnBDdku5wtdfcdwCe/3Aj07SJ+Ac7TJ8tHelPT6t9VzZMsfWKaBVf7EjUfDUyO9uOC\n",
              "AAABFkGbd0moQWyZTAh3//6plgAefddaoDnAA/NhEeHH7N0OBvsOxMR5uzWQpxgSdFJT2pcsdzKV\n",
              "8b4uIh51JEUVdtwmJ1f6wBWn7PDToNsPkmhYGsv5feRGxeekkjB4Wd9daqG84MX1z1WuC9My+45c\n",
              "4giWW0eagwOFOreVcHiBP7MiV5FMO2SnR9um/CBcEWiNcBD7suS6BKelBj86ZSPRIb50M/81YxYV\n",
              "fo2lBEgIWynO7r/FAJx0TKpesLw1F7qeGX0rktOMFN7+YQdaPeh3GBjj7ttCEXWTIUvvcN82cnaa\n",
              "wvVXITf+P/QKnlMotOvEaMD94+3sAyKyOjV3WNLvGIX7P1Ce7AVtcb91SFVzjjawOGi3BMHpAAAA\n",
              "y0GflUUVLDv/AA9GfMJ7mY+mEAEFmRV7uRp6hLlDHTi9gpbjYEHe0ULt9Sqt5fwqNtKMQbEs+7aY\n",
              "9xkqutSz70X3Lgg3HyWrgOyyNuhBfhKa3snsRHQr/j7/3Zm7ZM+gME0UUzq+iWflPD+tX6zTTS4R\n",
              "1nM6clYI2Wf+kEIvRfrl53aJ+S/PPEcK6BibMmQh64kSb0aXWm2oZ1XqmJG7waQsYDqnj6QxSpes\n",
              "nIqwJ390BuM0nyHZMAiQdtd7YLXJIyBFTAJQdqTidxsxAAAAiQGftHRDfwAWI7Z0VLgAIY9Zvx4Y\n",
              "tB6Hl8ZkTtgb66WC8I6ChMoOX2Du2j6TP0JqvS0uual1yvQfEJWSqrwk2obyTXccQkDD6kKnS830\n",
              "3W1E8ZcjWqrGL09tmBQi9JLrlCRTdW9lf4sOwAQHYVOOnk/1GW7RbFg5ETKmo9UTHviIprx2zQT2\n",
              "7Ds7AAAAwQGftmpDfwAVSfwVdbz/kQOwAhAos1L1EXo3xcOwuykHL2SFMK0eXLnmTB6GQh3OytEK\n",
              "FgiYa6FkKTfV8ytL+JxEHA8JbS3Tn4bXbeTP9Zc9dGKFu/iMCCErHJOG1DSlRI92cUpcK+znyvjH\n",
              "5R30/oDyyv/gYdMZoYUAPZLvEdDSTqxXcIOkZQ/KpUEZakCn1rPpISCvoZft7RGKOtkCagqE4bnv\n",
              "m8LWQX4yI7fwmQJu3j8/GVT7xDn79lzhelT1560AAADTQZu4SahBbJlMCG///qeEADs4/UdXcynI\n",
              "gAQ4g3TAAEsFu7HcjR6ly+BxrP3llwXxgS57+mkjzOM2UPOtBb9PHZspiB9sNsEV+Gc+gTmwGqiL\n",
              "ae+WKfDz1fZ+vBqH0Dq1BTf/1LX74M05nTxAS5H6Lh+29UoAC6mg+UmxB4ghg1aHbBS+inkSJy/M\n",
              "v5QYEEDIjF56D+//pYZ4vinbJgw9EcCABjJpQOgW/bDWbmXZeBEti3oSWT4RPNtYuyZyzZBAZjiz\n",
              "SSrmY5G1MpPG04nkLCWlBQAABFhtb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAJxAABAAAB\n",
              "AAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAAAAAAAAAACAAADgnRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAJ\n",
              "xAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAB9AAA\n",
              "AfQAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAACcQAAAgAAAEAAAAAAvptZGlhAAAAIG1kaGQA\n",
              "AAAAAAAAAAAAAAAAACgAAABkAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZp\n",
              "ZGVvSGFuZGxlcgAAAAKlbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAA\n",
              "AAAAAAABAAAADHVybCAAAAABAAACZXN0YmwAAAC5c3RzZAAAAAAAAAABAAAAqWF2YzEAAAAAAAAA\n",
              "AQAAAAAAAAAAAAAAAAAAAAAB9AH0AEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
              "AAAAAAAAAAAAAAAY//8AAAA3YXZjQwFkABb/4QAaZ2QAFqzZQIAQeeeEAAADAAQAAAMAUDxYtlgB\n",
              "AAZo6+PLIsD9+PgAAAAAHHV1aWRraEDyXyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEA\n",
              "AAAZAAAEAAAAABRzdHNzAAAAAAAAAAEAAAABAAAA0GN0dHMAAAAAAAAAGAAAAAEAAAgAAAAAAQAA\n",
              "EAAAAAACAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAI\n",
              "AAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQA\n",
              "AAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAA\n",
              "AAABAAAIAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAGQAAAAEAAAB4c3RzegAAAAAAAAAAAAAAGQAA\n",
              "H1EAAAGGAAAAqwAAAMUAAAEsAAAA1gAAAJsAAADYAAABhQAAAKAAAACyAAAAxQAAAmYAAADWAAAA\n",
              "pQAAANwAAADxAAABMwAAAMYAAACxAAABGgAAAM8AAACNAAAAxQAAANcAAAAUc3RjbwAAAAAAAAAB\n",
              "AAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAA\n",
              "AAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguNzYuMTAw\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Compare speed üöÄ\n",
        "\n",
        "We can then compare the speed of JaxMARL's MPE environments to the CPU-based ones provided by PettingZoo. We again take random actions and compare the number of environment steps per second between the two implementations.\n",
        "\n",
        "We also show how JaxMARL environments can be simply vectorised, using `jax.vmap`, to greatly increase the number of environment steps per second."
      ],
      "metadata": {
        "id": "XAIcs7kw2ROo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MPE_ENV = \"MPE_simple_reference_v3\""
      ],
      "metadata": {
        "id": "n_y9AyBcUU8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import jaxmarl\n",
        "import jax\n",
        "\n",
        "def make_benchmark(config):\n",
        "    env = jaxmarl.make(config[\"ENV_NAME\"], **config[\"ENV_KWARGS\"])\n",
        "    config[\"NUM_ACTORS\"] = env.num_agents * config[\"NUM_ENVS\"]\n",
        "\n",
        "    def benchmark(rng):\n",
        "        def init_runner_state(rng):\n",
        "\n",
        "            # INIT ENV\n",
        "            rng, _rng = jax.random.split(rng)\n",
        "            reset_rng = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
        "            obsv, env_state = jax.vmap(env.reset)(reset_rng)\n",
        "\n",
        "            return (env_state, obsv, rng)\n",
        "\n",
        "        def env_step(runner_state, unused):\n",
        "            env_state, last_obs, rng = runner_state\n",
        "\n",
        "            # SELECT ACTION\n",
        "            rng, _rng = jax.random.split(rng)\n",
        "            rngs = jax.random.split(_rng, config[\"NUM_ACTORS\"]).reshape((env.num_agents, config[\"NUM_ENVS\"], -1))\n",
        "            actions = {k: jax.vmap(env.action_space(k).sample)(rngs[i]) for i, k in enumerate(env.agents)}\n",
        "\n",
        "            # STEP ENV\n",
        "            rng, _rng = jax.random.split(rng)\n",
        "            rng_step = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
        "            obsv, env_state, _, _, info = jax.vmap(env.step)(\n",
        "                rng_step, env_state, actions\n",
        "            )\n",
        "            runner_state = (env_state, obsv, rng)\n",
        "            return runner_state, None\n",
        "\n",
        "        rng, init_rng = jax.random.split(rng)\n",
        "        runner_state = init_runner_state(init_rng)\n",
        "        runner_state = jax.lax.scan(env_step, runner_state, None, config[\"NUM_STEPS\"])\n",
        "        return runner_state\n",
        "\n",
        "    return benchmark"
      ],
      "metadata": {
        "id": "oRhtSTpYRg83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jaxmarl.environments.mpe.simple_world_comm import SimpleWorldCommMPE\n",
        "from pettingzoo.mpe import simple_v3, simple_tag_v3, simple_world_comm_v3, simple_reference_v3, simple_spread_v3, simple_crypto_v3, simple_speaker_listener_v4, simple_push_v3, simple_adversary_v3\n",
        "import time\n",
        "\n",
        "config = {\n",
        "    \"NUM_STEPS\": 1000,\n",
        "    \"NUM_ENVS\": 1000,\n",
        "    \"ACTIVATION\": \"relu\",\n",
        "    \"ENV_KWARGS\": {},\n",
        "    \"ENV_NAME\": MPE_ENV,\n",
        "    \"NUM_SEEDS\": 1,\n",
        "    \"SEED\": 0,\n",
        "}\n",
        "\n",
        "### JAXMARL BENCHMARK\n",
        "num_envs = [1, 100, 1000, 10000]\n",
        "jaxmarl_sps = []\n",
        "for num in num_envs:\n",
        "  config[\"NUM_ENVS\"] = num\n",
        "  benchmark_fn = jax.jit(make_benchmark(config))\n",
        "  rng = jax.random.PRNGKey(config[\"SEED\"])\n",
        "  rng, _rng = jax.random.split(rng)\n",
        "  benchmark_jit = jax.jit(benchmark_fn).lower(_rng).compile()\n",
        "  before = time.perf_counter_ns()\n",
        "  runner_state = jax.block_until_ready(benchmark_jit(_rng))\n",
        "  after = time.perf_counter_ns()\n",
        "  total_time = (after - before) / 1e9\n",
        "\n",
        "  sps = config['NUM_STEPS'] * config['NUM_ENVS'] / total_time\n",
        "  jaxmarl_sps.append(sps)\n",
        "\n",
        "  print(f\"JaxMARL, Num Envs: {num}, Total Time (s): {total_time}\")\n",
        "  print(f\"JaxMARL, Num Envs: {num}, Total Steps: {config['NUM_STEPS'] * config['NUM_ENVS']}\")\n",
        "  print(f\"JaxMARL, Num Envs: {num}, SPS: {sps}\")\n",
        "\n",
        "\n",
        "### PETTING ZOO BENCHMARK\n",
        "zoo_mpe_env_mapper = {\n",
        "    \"MPE_simple_v3\": simple_v3,\n",
        "    \"MPE_simple_world_comm_v3\": simple_world_comm_v3,\n",
        "    \"MPE_simple_tag_v3\": simple_tag_v3,\n",
        "    \"MPE_simple_spread_v3\": simple_spread_v3,\n",
        "    \"MPE_simple_crypto_v3\": simple_crypto_v3,\n",
        "    \"MPE_simple_speaker_listener_v4\": simple_speaker_listener_v4,\n",
        "    \"MPE_simple_push_v3\": simple_push_v3,\n",
        "    \"MPE_simple_adversary_v3\": simple_adversary_v3,\n",
        "    \"MPE_simple_reference_v3\": simple_reference_v3,\n",
        "}\n",
        "zoo_env = zoo_mpe_env_mapper[config[\"ENV_NAME\"]]\n",
        "env = zoo_env.parallel_env(max_cycles=max_steps)\n",
        "obs = env.reset()\n",
        "\n",
        "start_time = time.time()\n",
        "actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
        "\n",
        "for _ in range(config[\"NUM_STEPS\"]):\n",
        "    actions = {agent: env.action_space(agent).sample() for agent in env.agents}  # this is where you would insert your policy\n",
        "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
        "\n",
        "zoo_time = time.time() - start_time\n",
        "zoo_sps = config[\"NUM_STEPS\"]/zoo_time\n",
        "\n",
        "\n",
        "print(f\"PettingZoo Total Time (s): {zoo_time}\")\n",
        "print(f\"PettingZoo Total Steps: {config['NUM_STEPS']}\")\n",
        "print(f\"PettingZoo SPS: {zoo_sps}\")\n"
      ],
      "metadata": {
        "id": "h9VtVKgbRyMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(num_envs, jaxmarl_sps, linestyle='--', marker='o', label=\"JAX\")\n",
        "plt.axhline(y=zoo_sps, color='r', linestyle='--', label=\"PettingZoo\")\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel(\"Steps per Second\")\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Number of parallel environments\")\n",
        "plt.title(f\"Steps per second for {MPE_ENV}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6YLL7Aj-ShER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Train an agent üç≤\n",
        "\n",
        "We train an agent on the `cramped_room` Overcooked scenario using IPPO, our IPPO code is based off [PureJaxRL](https://github.com/luchris429/purejaxrl). Here we also show how `jax.vmap` can again be used to simply train over multiple seeds."
      ],
      "metadata": {
        "id": "WobTKkl25IlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import numpy as np\n",
        "import optax\n",
        "from flax.linen.initializers import constant, orthogonal\n",
        "from typing import Sequence, NamedTuple, Any\n",
        "from flax.training.train_state import TrainState\n",
        "import distrax\n",
        "from gymnax.wrappers.purerl import LogWrapper, FlattenObservationWrapper\n",
        "import jaxmarl\n",
        "from jaxmarl.wrappers.baselines import LogWrapper\n",
        "from jaxmarl.environments.overcooked import overcooked_layouts\n",
        "from jaxmarl.viz.overcooked_visualizer import OvercookedVisualizer\n",
        "import hydra\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    action_dim: Sequence[int]\n",
        "    activation: str = \"tanh\"\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        if self.activation == \"relu\":\n",
        "            activation = nn.relu\n",
        "        else:\n",
        "            activation = nn.tanh\n",
        "        actor_mean = nn.Dense(\n",
        "            64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
        "        )(x)\n",
        "        actor_mean = activation(actor_mean)\n",
        "        actor_mean = nn.Dense(\n",
        "            64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
        "        )(actor_mean)\n",
        "        actor_mean = activation(actor_mean)\n",
        "        actor_mean = nn.Dense(\n",
        "            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\n",
        "        )(actor_mean)\n",
        "        pi = distrax.Categorical(logits=actor_mean)\n",
        "\n",
        "        critic = nn.Dense(\n",
        "            64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
        "        )(x)\n",
        "        critic = activation(critic)\n",
        "        critic = nn.Dense(\n",
        "            64, kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
        "        )(critic)\n",
        "        critic = activation(critic)\n",
        "        critic = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(\n",
        "            critic\n",
        "        )\n",
        "\n",
        "        return pi, jnp.squeeze(critic, axis=-1)\n",
        "\n",
        "\n",
        "class Transition(NamedTuple):\n",
        "    done: jnp.ndarray\n",
        "    action: jnp.ndarray\n",
        "    value: jnp.ndarray\n",
        "    reward: jnp.ndarray\n",
        "    log_prob: jnp.ndarray\n",
        "    obs: jnp.ndarray\n",
        "    info: jnp.ndarray\n",
        "\n",
        "def get_rollout(train_state, config):\n",
        "    env = jaxmarl.make(config[\"ENV_NAME\"], **config[\"ENV_KWARGS\"])\n",
        "\n",
        "    network = ActorCritic(env.action_space().n, activation=config[\"ACTIVATION\"])\n",
        "    key = jax.random.PRNGKey(0)\n",
        "    key, key_r, key_a = jax.random.split(key, 3)\n",
        "\n",
        "    init_x = jnp.zeros(env.observation_space().shape)\n",
        "    init_x = init_x.flatten()\n",
        "\n",
        "    network.init(key_a, init_x)\n",
        "    network_params = train_state.params\n",
        "\n",
        "    done = False\n",
        "\n",
        "    obs, state = env.reset(key_r)\n",
        "    state_seq = [state]\n",
        "    while not done:\n",
        "        key, key_a0, key_a1, key_s = jax.random.split(key, 4)\n",
        "\n",
        "        # obs_batch = batchify(obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "        # breakpoint()\n",
        "        obs = {k: v.flatten() for k, v in obs.items()}\n",
        "\n",
        "        pi_0, _ = network.apply(network_params, obs[\"agent_0\"])\n",
        "        pi_1, _ = network.apply(network_params, obs[\"agent_1\"])\n",
        "\n",
        "        actions = {\"agent_0\": pi_0.sample(seed=key_a0), \"agent_1\": pi_1.sample(seed=key_a1)}\n",
        "        # env_act = unbatchify(action, env.agents, config[\"NUM_ENVS\"], env.num_agents)\n",
        "        # env_act = {k: v.flatten() for k, v in env_act.items()}\n",
        "\n",
        "        # STEP ENV\n",
        "        obs, state, reward, done, info = env.step(key_s, state, actions)\n",
        "        done = done[\"__all__\"]\n",
        "\n",
        "        state_seq.append(state)\n",
        "\n",
        "    return state_seq\n",
        "\n",
        "def batchify(x: dict, agent_list, num_actors):\n",
        "    x = jnp.stack([x[a] for a in agent_list])\n",
        "    return x.reshape((num_actors, -1))\n",
        "\n",
        "\n",
        "def unbatchify(x: jnp.ndarray, agent_list, num_envs, num_actors):\n",
        "    x = x.reshape((num_actors, num_envs, -1))\n",
        "    return {a: x[i] for i, a in enumerate(agent_list)}\n",
        "\n",
        "def make_train(config):\n",
        "    env = jaxmarl.make(config[\"ENV_NAME\"], **config[\"ENV_KWARGS\"])\n",
        "\n",
        "    config[\"NUM_ACTORS\"] = env.num_agents * config[\"NUM_ENVS\"]\n",
        "    config[\"NUM_UPDATES\"] = (\n",
        "        config[\"TOTAL_TIMESTEPS\"] // config[\"NUM_STEPS\"] // config[\"NUM_ENVS\"]\n",
        "    )\n",
        "    config[\"MINIBATCH_SIZE\"] = (\n",
        "        config[\"NUM_ACTORS\"] * config[\"NUM_STEPS\"] // config[\"NUM_MINIBATCHES\"]\n",
        "    )\n",
        "\n",
        "    env = LogWrapper(env)\n",
        "\n",
        "    def linear_schedule(count):\n",
        "        frac = 1.0 - (count // (config[\"NUM_MINIBATCHES\"] * config[\"UPDATE_EPOCHS\"])) / config[\"NUM_UPDATES\"]\n",
        "        return config[\"LR\"] * frac\n",
        "\n",
        "    def train(rng):\n",
        "\n",
        "        # INIT NETWORK\n",
        "        network = ActorCritic(env.action_space().n, activation=config[\"ACTIVATION\"])\n",
        "        rng, _rng = jax.random.split(rng)\n",
        "        init_x = jnp.zeros(env.observation_space().shape)\n",
        "\n",
        "        init_x = init_x.flatten()\n",
        "\n",
        "        network_params = network.init(_rng, init_x)\n",
        "        if config[\"ANNEAL_LR\"]:\n",
        "            tx = optax.chain(\n",
        "                optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
        "                optax.adam(learning_rate=linear_schedule, eps=1e-5),\n",
        "            )\n",
        "        else:\n",
        "            tx = optax.chain(optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]), optax.adam(config[\"LR\"], eps=1e-5))\n",
        "        train_state = TrainState.create(\n",
        "            apply_fn=network.apply,\n",
        "            params=network_params,\n",
        "            tx=tx,\n",
        "        )\n",
        "\n",
        "        # INIT ENV\n",
        "        rng, _rng = jax.random.split(rng)\n",
        "        reset_rng = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
        "        obsv, env_state = jax.vmap(env.reset, in_axes=(0,))(reset_rng)\n",
        "\n",
        "        # TRAIN LOOP\n",
        "        def _update_step(runner_state, unused):\n",
        "            # COLLECT TRAJECTORIES\n",
        "            def _env_step(runner_state, unused):\n",
        "                train_state, env_state, last_obs, rng = runner_state\n",
        "\n",
        "                # SELECT ACTION\n",
        "                rng, _rng = jax.random.split(rng)\n",
        "\n",
        "                obs_batch = batchify(last_obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "\n",
        "                pi, value = network.apply(train_state.params, obs_batch)\n",
        "                action = pi.sample(seed=_rng)\n",
        "                log_prob = pi.log_prob(action)\n",
        "                env_act = unbatchify(action, env.agents, config[\"NUM_ENVS\"], env.num_agents)\n",
        "\n",
        "                env_act = {k:v.flatten() for k,v in env_act.items()}\n",
        "\n",
        "                # STEP ENV\n",
        "                rng, _rng = jax.random.split(rng)\n",
        "                rng_step = jax.random.split(_rng, config[\"NUM_ENVS\"])\n",
        "\n",
        "                obsv, env_state, reward, done, info = jax.vmap(env.step, in_axes=(0,0,0))(\n",
        "                    rng_step, env_state, env_act\n",
        "                )\n",
        "                info = jax.tree_map(lambda x: x.reshape((config[\"NUM_ACTORS\"])), info)\n",
        "                transition = Transition(\n",
        "                    batchify(done, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
        "                    action,\n",
        "                    value,\n",
        "                    batchify(reward, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
        "                    log_prob,\n",
        "                    obs_batch,\n",
        "                    info\n",
        "\n",
        "                )\n",
        "                runner_state = (train_state, env_state, obsv, rng)\n",
        "                return runner_state, transition\n",
        "\n",
        "            runner_state, traj_batch = jax.lax.scan(\n",
        "                _env_step, runner_state, None, config[\"NUM_STEPS\"]\n",
        "            )\n",
        "\n",
        "            # CALCULATE ADVANTAGE\n",
        "            train_state, env_state, last_obs, rng = runner_state\n",
        "            last_obs_batch = batchify(last_obs, env.agents, config[\"NUM_ACTORS\"])\n",
        "            _, last_val = network.apply(train_state.params, last_obs_batch)\n",
        "\n",
        "            def _calculate_gae(traj_batch, last_val):\n",
        "                def _get_advantages(gae_and_next_value, transition):\n",
        "                    gae, next_value = gae_and_next_value\n",
        "                    done, value, reward = (\n",
        "                        transition.done,\n",
        "                        transition.value,\n",
        "                        transition.reward,\n",
        "                    )\n",
        "                    delta = reward + config[\"GAMMA\"] * next_value * (1 - done) - value\n",
        "                    gae = (\n",
        "                        delta\n",
        "                        + config[\"GAMMA\"] * config[\"GAE_LAMBDA\"] * (1 - done) * gae\n",
        "                    )\n",
        "                    return (gae, value), gae\n",
        "\n",
        "                _, advantages = jax.lax.scan(\n",
        "                    _get_advantages,\n",
        "                    (jnp.zeros_like(last_val), last_val),\n",
        "                    traj_batch,\n",
        "                    reverse=True,\n",
        "                    unroll=16,\n",
        "                )\n",
        "                return advantages, advantages + traj_batch.value\n",
        "\n",
        "            advantages, targets = _calculate_gae(traj_batch, last_val)\n",
        "\n",
        "            # UPDATE NETWORK\n",
        "            def _update_epoch(update_state, unused):\n",
        "                def _update_minbatch(train_state, batch_info):\n",
        "                    traj_batch, advantages, targets = batch_info\n",
        "\n",
        "                    def _loss_fn(params, traj_batch, gae, targets):\n",
        "                        # RERUN NETWORK\n",
        "                        pi, value = network.apply(params, traj_batch.obs)\n",
        "                        log_prob = pi.log_prob(traj_batch.action)\n",
        "\n",
        "                        # CALCULATE VALUE LOSS\n",
        "                        value_pred_clipped = traj_batch.value + (\n",
        "                            value - traj_batch.value\n",
        "                        ).clip(-config[\"CLIP_EPS\"], config[\"CLIP_EPS\"])\n",
        "                        value_losses = jnp.square(value - targets)\n",
        "                        value_losses_clipped = jnp.square(value_pred_clipped - targets)\n",
        "                        value_loss = (\n",
        "                            0.5 * jnp.maximum(value_losses, value_losses_clipped).mean()\n",
        "                        )\n",
        "\n",
        "                        # CALCULATE ACTOR LOSS\n",
        "                        ratio = jnp.exp(log_prob - traj_batch.log_prob)\n",
        "                        gae = (gae - gae.mean()) / (gae.std() + 1e-8)\n",
        "                        loss_actor1 = ratio * gae\n",
        "                        loss_actor2 = (\n",
        "                            jnp.clip(\n",
        "                                ratio,\n",
        "                                1.0 - config[\"CLIP_EPS\"],\n",
        "                                1.0 + config[\"CLIP_EPS\"],\n",
        "                            )\n",
        "                            * gae\n",
        "                        )\n",
        "                        loss_actor = -jnp.minimum(loss_actor1, loss_actor2)\n",
        "                        loss_actor = loss_actor.mean()\n",
        "                        entropy = pi.entropy().mean()\n",
        "\n",
        "                        total_loss = (\n",
        "                            loss_actor\n",
        "                            + config[\"VF_COEF\"] * value_loss\n",
        "                            - config[\"ENT_COEF\"] * entropy\n",
        "                        )\n",
        "                        return total_loss, (value_loss, loss_actor, entropy)\n",
        "\n",
        "                    grad_fn = jax.value_and_grad(_loss_fn, has_aux=True)\n",
        "                    total_loss, grads = grad_fn(\n",
        "                        train_state.params, traj_batch, advantages, targets\n",
        "                    )\n",
        "                    train_state = train_state.apply_gradients(grads=grads)\n",
        "                    return train_state, total_loss\n",
        "\n",
        "                train_state, traj_batch, advantages, targets, rng = update_state\n",
        "                rng, _rng = jax.random.split(rng)\n",
        "                batch_size = config[\"MINIBATCH_SIZE\"] * config[\"NUM_MINIBATCHES\"]\n",
        "                assert (\n",
        "                    batch_size == config[\"NUM_STEPS\"] * config[\"NUM_ACTORS\"]\n",
        "                ), \"batch size must be equal to number of steps * number of actors\"\n",
        "                permutation = jax.random.permutation(_rng, batch_size)\n",
        "                batch = (traj_batch, advantages, targets)\n",
        "                batch = jax.tree_util.tree_map(\n",
        "                    lambda x: x.reshape((batch_size,) + x.shape[2:]), batch\n",
        "                )\n",
        "                shuffled_batch = jax.tree_util.tree_map(\n",
        "                    lambda x: jnp.take(x, permutation, axis=0), batch\n",
        "                )\n",
        "                minibatches = jax.tree_util.tree_map(\n",
        "                    lambda x: jnp.reshape(\n",
        "                        x, [config[\"NUM_MINIBATCHES\"], -1] + list(x.shape[1:])\n",
        "                    ),\n",
        "                    shuffled_batch,\n",
        "                )\n",
        "                train_state, total_loss = jax.lax.scan(\n",
        "                    _update_minbatch, train_state, minibatches\n",
        "                )\n",
        "                update_state = (train_state, traj_batch, advantages, targets, rng)\n",
        "                return update_state, total_loss\n",
        "\n",
        "            update_state = (train_state, traj_batch, advantages, targets, rng)\n",
        "            update_state, loss_info = jax.lax.scan(\n",
        "                _update_epoch, update_state, None, config[\"UPDATE_EPOCHS\"]\n",
        "            )\n",
        "            train_state = update_state[0]\n",
        "            metric = traj_batch.info\n",
        "            rng = update_state[-1]\n",
        "\n",
        "            runner_state = (train_state, env_state, last_obs, rng)\n",
        "            return runner_state, metric\n",
        "\n",
        "        rng, _rng = jax.random.split(rng)\n",
        "        runner_state = (train_state, env_state, obsv, _rng)\n",
        "        runner_state, metric = jax.lax.scan(\n",
        "            _update_step, runner_state, None, config[\"NUM_UPDATES\"]\n",
        "        )\n",
        "        return {\"runner_state\": runner_state, \"metrics\": metric}\n",
        "\n",
        "    return train\n",
        "\n"
      ],
      "metadata": {
        "id": "wGwk68jK2VPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# set hyperparameters:\n",
        "config = {\n",
        "    \"LR\": 2.5e-4,\n",
        "    \"NUM_ENVS\": 16,\n",
        "    \"NUM_STEPS\": 128,\n",
        "    \"TOTAL_TIMESTEPS\": 5e6,\n",
        "    \"UPDATE_EPOCHS\": 4,\n",
        "    \"NUM_MINIBATCHES\": 4,\n",
        "    \"GAMMA\": 0.99,\n",
        "    \"GAE_LAMBDA\": 0.95,\n",
        "    \"CLIP_EPS\": 0.2,\n",
        "    \"ENT_COEF\": 0.01,\n",
        "    \"VF_COEF\": 0.5,\n",
        "    \"MAX_GRAD_NORM\": 0.5,\n",
        "    \"ACTIVATION\": \"tanh\",\n",
        "    \"ENV_NAME\": \"overcooked\",\n",
        "    \"ENV_KWARGS\": {\n",
        "      \"layout\" : \"cramped_room\"\n",
        "    },\n",
        "    \"ANNEAL_LR\": True,\n",
        "    \"SEED\": 0,\n",
        "    \"NUM_SEEDS\": 3\n",
        "}\n",
        "\n",
        "config[\"ENV_KWARGS\"][\"layout\"] = overcooked_layouts[config[\"ENV_KWARGS\"][\"layout\"]]\n",
        "rng = jax.random.PRNGKey(config[\"SEED\"])\n",
        "rngs = jax.random.split(rng, config[\"NUM_SEEDS\"])\n",
        "with jax.disable_jit(False):\n",
        "    train_jit = jax.jit(jax.vmap(make_train(config)))\n",
        "    out = train_jit(rngs)\n",
        "\n",
        "\n",
        "for i in range(config[\"NUM_SEEDS\"]):\n",
        "    plt.plot(out[\"metrics\"][\"returned_episode_returns\"][i].mean(-1).reshape(-1))\n",
        "plt.xlabel(\"Update Step\")\n",
        "plt.ylabel(\"Return\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AxrH1jHv3orP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.animation as animation\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import distrax\n",
        "from jaxmarl import make\n",
        "from jaxmarl.environments.smax import map_name_to_scenario\n",
        "from jaxmarl.environments.smax.heuristic_enemy import (\n",
        "    create_heuristic_policy,\n",
        "    get_heuristic_policy_initial_state,\n",
        ")\n",
        "from jaxmarl.viz.visualizer import Visualizer, SMAXVisualizer\n",
        "import os\n",
        "from typing import Sequence\n",
        "\n",
        "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "# Parameters + random keys\n",
        "max_steps = 30\n",
        "key = jax.random.PRNGKey(2)\n",
        "key, key_r, key_a, key_p = jax.random.split(key, 4)\n",
        "\n",
        "\n",
        "class LearnedPolicy(nn.Module):\n",
        "    action_dim: Sequence[int]\n",
        "    activation: str = \"tanh\"\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        if self.activation == \"relu\":\n",
        "            activation = nn.relu\n",
        "        else:\n",
        "            activation = nn.tanh\n",
        "        actor_mean = nn.Dense(self.action_dim)(x)\n",
        "        actor_mean = activation(actor_mean)\n",
        "        pi = distrax.Categorical(logits=actor_mean)\n",
        "\n",
        "        critic = nn.Dense(1)(x)\n",
        "        critic = activation(critic)\n",
        "\n",
        "        return pi, jnp.squeeze(critic, axis=-1)\n",
        "\n",
        "\n",
        "def init_policy(env, rng):\n",
        "    network = LearnedPolicy(env.action_space(env.agents[0]).n, activation=\"tanh\")\n",
        "    rng, _rng = jax.random.split(rng)\n",
        "    init_x = jnp.zeros(env.observation_space(env.agents[0]).shape)\n",
        "    params = network.init(_rng, init_x)\n",
        "    return params\n",
        "\n",
        "\n",
        "# Instantiate environment\n",
        "with jax.disable_jit(False):\n",
        "    # scenario = map_name_to_scenario(\"5m_vs_6m\")\n",
        "    env = make(\n",
        "        \"SMAX\",\n",
        "        # attack_mode=\"random\",\n",
        "        # scenario=scenario,\n",
        "        use_self_play_reward=False,\n",
        "        walls_cause_death=True,\n",
        "        see_enemy_actions=False,\n",
        "        num_allies=3,\n",
        "        num_enemies=5,\n",
        "        smacv2_position_generation=True,\n",
        "        smacv2_unit_type_generation=True,\n",
        "    )\n",
        "    # env = make(\"SMAX\")\n",
        "    # params = init_policy(env, key_p)\n",
        "    # learned_policy = LearnedPolicy(env.action_space(env.agents[0]).n, activation=\"tanh\")\n",
        "    # env = make(\"LearnedPolicyEnemySMAX\", params=params, policy=learned_policy)\n",
        "    obs, state = env.reset(key_r)\n",
        "    print(\"list of agents in environment\", env.agents)\n",
        "\n",
        "    # Sample random actions\n",
        "    key_a = jax.random.split(key_a, env.num_agents)\n",
        "    actions = {\n",
        "        agent: env.action_space(agent).sample(key_a[i])\n",
        "        for i, agent in enumerate(env.agents)\n",
        "    }\n",
        "    print(\"example action dict\", actions)\n",
        "\n",
        "    policy_states = {\n",
        "        agent: get_heuristic_policy_initial_state() for agent in env.agents\n",
        "    }\n",
        "    policy = create_heuristic_policy(env, 0, shoot=True, attack_mode=\"closest\")\n",
        "    enemy_policy = create_heuristic_policy(env, 1, shoot=True, attack_mode=\"closest\")\n",
        "    state_seq = []\n",
        "    returns = {a: 0 for a in env.agents}\n",
        "    for i in range(max_steps):\n",
        "        # Iterate random keys and sample actions\n",
        "        key, key_s, key_seq = jax.random.split(key, 3)\n",
        "        key_a = jax.random.split(key_seq, env.num_agents)\n",
        "        actions = {}\n",
        "        for i, agent in enumerate(env.agents):\n",
        "            p = policy if i < env.num_allies else enemy_policy\n",
        "            action, policy_state = p(key_a[i], policy_states[agent], obs[agent])\n",
        "            policy_states[agent] = policy_state\n",
        "            actions[agent] = action\n",
        "\n",
        "        # actions = {agent: jnp.array(1) for agent in env.agents}\n",
        "        # actions = {agent: env.action_space(agent).sample(key_a[i]) for i, agent in enumerate(env.agents)}\n",
        "        state_seq.append((key_s, state, actions))\n",
        "        # Step environment\n",
        "        avail_actions = env.get_avail_actions(state)\n",
        "        obs, state, rewards, dones, infos = env.step(key_s, state, actions)\n",
        "        print(f\"Actions: {actions}\")\n",
        "        returns = {a: returns[a] + rewards[a] for a in env.agents}\n",
        "        if dones[\"__all__\"]:\n",
        "            print(f\"Returns: {returns}\")\n",
        "print(f\"Returns: {returns}\")\n",
        "\n",
        "#viz.animate(view=False, save_fname=\"output.gif\")\n",
        "viz.animate(view=True)\n",
        "\n",
        "\"\"\"\n",
        "viz = SMAXVisualizer(env, state_seq)\n",
        "ani = animation.FuncAnimation(\n",
        "    viz.fig,\n",
        "    viz.update,\n",
        "    frames=len(viz.state_seq),\n",
        "    blit=False,\n",
        "    interval=viz.interval,\n",
        ")\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_html5_video())\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "lN6EBp3EtKNq",
        "outputId": "53436111-fc61-4c70-86f2-d058d8554668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list of agents in environment ['ally_0', 'ally_1', 'ally_2', 'enemy_0', 'enemy_1', 'enemy_2', 'enemy_3', 'enemy_4']\n",
            "example action dict {'ally_0': Array(3, dtype=int32), 'ally_1': Array(6, dtype=int32), 'ally_2': Array(3, dtype=int32), 'enemy_0': Array(6, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(2, dtype=int32), 'enemy_3': Array(0, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(5, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(5, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(1, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(5, dtype=int32), 'enemy_4': Array(5, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(3, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(3, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(7, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(6, dtype=int32)}\n",
            "Returns: {'ally_0': Array(0.44500005, dtype=float32), 'ally_1': Array(0.44500005, dtype=float32), 'ally_2': Array(0.44500005, dtype=float32), 'enemy_0': Array(2., dtype=float32), 'enemy_1': Array(2., dtype=float32), 'enemy_2': Array(2., dtype=float32), 'enemy_3': Array(2., dtype=float32), 'enemy_4': Array(2., dtype=float32)}\n",
            "Actions: {'ally_0': Array(3, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(2, dtype=int32), 'enemy_0': Array(0, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(0, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(0, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(2, dtype=int32), 'enemy_0': Array(1, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(1, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(5, dtype=int32)}\n",
            "Actions: {'ally_0': Array(3, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(1, dtype=int32), 'enemy_1': Array(5, dtype=int32), 'enemy_2': Array(1, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(5, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(8, dtype=int32), 'enemy_0': Array(5, dtype=int32), 'enemy_1': Array(5, dtype=int32), 'enemy_2': Array(1, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(5, dtype=int32)}\n",
            "Actions: {'ally_0': Array(3, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(1, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(1, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(6, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(8, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(6, dtype=int32), 'enemy_1': Array(6, dtype=int32), 'enemy_2': Array(6, dtype=int32), 'enemy_3': Array(6, dtype=int32), 'enemy_4': Array(6, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(2, dtype=int32), 'enemy_1': Array(2, dtype=int32), 'enemy_2': Array(2, dtype=int32), 'enemy_3': Array(2, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(3, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(2, dtype=int32), 'enemy_1': Array(1, dtype=int32), 'enemy_2': Array(2, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(1, dtype=int32)}\n",
            "Actions: {'ally_0': Array(0, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(2, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(2, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Actions: {'ally_0': Array(5, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(0, dtype=int32), 'enemy_0': Array(7, dtype=int32), 'enemy_1': Array(7, dtype=int32), 'enemy_2': Array(7, dtype=int32), 'enemy_3': Array(7, dtype=int32), 'enemy_4': Array(7, dtype=int32)}\n",
            "Returns: {'ally_0': Array(0.52825, dtype=float32), 'ally_1': Array(0.52825, dtype=float32), 'ally_2': Array(0.52825, dtype=float32), 'enemy_0': Array(4., dtype=float32), 'enemy_1': Array(4., dtype=float32), 'enemy_2': Array(4., dtype=float32), 'enemy_3': Array(4., dtype=float32), 'enemy_4': Array(4., dtype=float32)}\n",
            "Actions: {'ally_0': Array(1, dtype=int32), 'ally_1': Array(0, dtype=int32), 'ally_2': Array(1, dtype=int32), 'enemy_0': Array(3, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(3, dtype=int32), 'enemy_3': Array(3, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Actions: {'ally_0': Array(2, dtype=int32), 'ally_1': Array(1, dtype=int32), 'ally_2': Array(1, dtype=int32), 'enemy_0': Array(2, dtype=int32), 'enemy_1': Array(0, dtype=int32), 'enemy_2': Array(3, dtype=int32), 'enemy_3': Array(0, dtype=int32), 'enemy_4': Array(2, dtype=int32)}\n",
            "Returns: {'ally_0': Array(0.52825, dtype=float32), 'ally_1': Array(0.52825, dtype=float32), 'ally_2': Array(0.52825, dtype=float32), 'enemy_0': Array(4., dtype=float32), 'enemy_1': Array(4., dtype=float32), 'enemy_2': Array(4., dtype=float32), 'enemy_3': Array(4., dtype=float32), 'enemy_4': Array(4., dtype=float32)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/matplotlib/animation.py:884: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nviz = SMAXVisualizer(env, state_seq)\\nani = animation.FuncAnimation(\\n    viz.fig,\\n    viz.update,\\n    frames=len(viz.state_seq),\\n    blit=False,\\n    interval=viz.interval,\\n)\\n\\nfrom IPython.display import HTML\\nHTML(ani.to_html5_video())\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}